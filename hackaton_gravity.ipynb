{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1958671875\n"
     ]
    }
   ],
   "source": [
    "# See how much memory is used by OS initially.\n",
    "# Then substract this value from later mem used, to obtain mem used by scripts.\n",
    "import psutil\n",
    "GB_UNIT = 1000*1024**2\n",
    "MB_UNIT = GB_UNIT/1e3\n",
    "OS_MEM = psutil.virtual_memory().used\n",
    "print(OS_MEM/GB_UNIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************* Initialization *********************\n",
      "# Initial conditions for neutrinos:\n",
      "PHIs = 20, THETAs=20, Vs=200\n",
      "Total neutrinos: 80000\n",
      "# Simulation parameters:\n",
      "Simulation box: L025N752\n",
      "Snapshot from 0036 (z=0) to 0013 (z=4)\n",
      "Pre/Sim CPUs 10/128\n",
      "DM limit for cells: 10\n",
      "# File management:\n",
      "Box files directory: \n",
      " /projects/0/einf180/Tango_sims/L025N752/DMONLY/SigmaConstant00\n",
      "Output directory: \n",
      " /gpfs/home4/zimmer/neutrino_clustering_V2/L025N752/DMONLY/SigmaConstant00\n",
      "**********************************************************\n",
      "********Number density band********\n",
      "Halo batch params (Rvir,Mvir,cNFW):\n",
      "[[253.5523526   12.24058042   6.9286026 ]\n",
      " [158.62979351  11.62953177   8.03988676]\n",
      " [137.07912107  11.43929142   9.41292697]\n",
      " [141.82849159  11.48366794   2.6088865 ]\n",
      " [306.35586267  12.48705608  11.48652354]\n",
      " [190.92998087  11.87099988   7.03921462]\n",
      " [240.52254202  12.17184485   7.39127504]\n",
      " [169.32112452  11.71451092   8.23421103]\n",
      " [167.71139596  11.70206521   7.62954256]\n",
      " [168.53268315  11.7084299    9.38434194]]\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "from shared.preface import *\n",
    "import shared.functions as fct\n",
    "\n",
    "# Initialize parameters and files.\n",
    "PRE = PRE(\n",
    "    sim='L025N752', \n",
    "    z0_snap=36, z4_snap=13, DM_lim=10,\n",
    "    sim_dir=SIM_ROOT, sim_ver=SIM_TYPE,\n",
    "    phis=20, thetas=20, vels=200,\n",
    "    pre_CPUs=10, sim_CPUs=128\n",
    ")\n",
    "\n",
    "\n",
    "TEMP_DIR = f'X_tests'\n",
    "\n",
    "Testing = False\n",
    "if Testing:\n",
    "    mass_gauge = 12.3\n",
    "    mass_range = 0.3\n",
    "    size = 1\n",
    "else:\n",
    "    mass_gauge = 12.0\n",
    "    mass_range = 0.6\n",
    "    size = 10\n",
    "\n",
    "hname = f'1e+{mass_gauge}_pm{mass_range}Msun'\n",
    "fct.halo_batch_indices(\n",
    "    PRE.Z0_STR, mass_gauge, mass_range, 'halos', size, \n",
    "    hname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "halo_batch_IDs = np.load(f'{TEMP_DIR}/halo_batch_{hname}_indices.npy')\n",
    "halo_batch_params = np.load(f'{TEMP_DIR}/halo_batch_{hname}_params.npy')\n",
    "halo_num = len(halo_batch_params)\n",
    "\n",
    "print('********Number density band********')\n",
    "print('Halo batch params (Rvir,Mvir,cNFW):')\n",
    "print(halo_batch_params)\n",
    "print('***********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "halo 3/10 ; snapshot 0036\n"
     ]
    }
   ],
   "source": [
    "# =============================================== #\n",
    "# Run precalculations for selected halo in batch. #\n",
    "# =============================================== #\n",
    "\n",
    "halo_j = 2\n",
    "halo_ID = halo_batch_IDs[halo_j]\n",
    "\n",
    "# Generate progenitor index array for current halo.\n",
    "splits = re.split('/', SIM_TYPE)\n",
    "MTname = f'{PRE.SIM}_{splits[0]}_{splits[1]}'\n",
    "proj_IDs = fct.read_MergerTree(PRE.OUT_DIR, MTname, halo_ID)\n",
    "\n",
    "# Create empty arrays to save specifics of each loop.\n",
    "save_GRID_L = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "save_num_DM = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "save_DM_com = []\n",
    "\n",
    "# for j, (snap, proj_ID) in enumerate(zip(\n",
    "#     PRE.NUMS_SNAPS[::-1], proj_IDs\n",
    "# )):\n",
    "\n",
    "j = 0\n",
    "snap = PRE.NUMS_SNAPS[::-1][0]\n",
    "proj_ID = proj_IDs[0]\n",
    "\n",
    "proj_ID = int(proj_ID)\n",
    "\n",
    "# Output halo progress.\n",
    "print(f'halo {halo_j+1}/{halo_num} ; snapshot {snap}')\n",
    "\n",
    "\n",
    "# --------------------------- #\n",
    "# Read and load DM positions. #\n",
    "# --------------------------- #\n",
    "\n",
    "# Define how many shells are used, out of len(DM_SHELL_EDGES)-1.\n",
    "shells = 1\n",
    "DM_shell_edges = DM_SHELL_EDGES[:shells+1]\n",
    "\n",
    "IDname = f'origID{halo_ID}_snap_{snap}'\n",
    "fct.read_DM_all_inRange(\n",
    "    snap, proj_ID, DM_shell_edges, IDname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "\n",
    "# Load DM from all used shells.\n",
    "DM_pre = []\n",
    "for si in range(shells):\n",
    "    DM_pre.append(np.load(f'{TEMP_DIR}/DM_pos_{IDname}_shell{si}.npy'))\n",
    "DM_raw = np.array(list(chain.from_iterable(DM_pre)))\n",
    "del DM_pre\n",
    "\n",
    "# Save c.o.m. coord of all DM particles (for outside_gravity fct.).\n",
    "save_DM_com.append(np.sum(DM_raw, axis=0)/len(DM_raw))\n",
    "\n",
    "# ---------------------- #\n",
    "# Cell division process. #\n",
    "# ---------------------- #\n",
    "\n",
    "# Initialize grid.\n",
    "snap_GRID_L = (int(np.abs(DM_raw).max()) + 1)*kpc\n",
    "raw_grid = fct.grid_3D(snap_GRID_L, snap_GRID_L)\n",
    "init_grid = np.expand_dims(raw_grid, axis=1)\n",
    "\n",
    "# Prepare arrays for cell division.\n",
    "DM_raw *= kpc\n",
    "DM_pos = np.expand_dims(DM_raw, axis=0)\n",
    "DM_pos_for_cell_division = np.repeat(DM_pos, len(init_grid), axis=0)\n",
    "\n",
    "# Cell division.\n",
    "cell_division_count = fct.cell_division(\n",
    "    init_grid, DM_pos_for_cell_division, snap_GRID_L, PRE.DM_LIM, None, TEMP_DIR, IDname\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory():\n",
    "    mem_free = psutil.virtual_memory().available\n",
    "    mem_used = psutil.virtual_memory().used\n",
    "    cores = psutil.cpu_count()\n",
    "    print(mem_free/GB_UNIT)\n",
    "    print(mem_used/GB_UNIT)\n",
    "\n",
    "def cell_gravity_short_range(\n",
    "    cell_coords, cell_gen, init_GRID_S,\n",
    "    DM_pos, DM_lim, DM_sim_mass, smooth_l,\n",
    "    out_dir, fname\n",
    "):\n",
    "    # Center all DM positions w.r.t. cell center.\n",
    "    DM_pos -= cell_coords\n",
    "\n",
    "    # Cell lengths to limit DM particles. Limit for the largest cell is \n",
    "    # GRID_S/2, not just GRID_S, therefore the cell_gen+1 !\n",
    "    cell_len = np.expand_dims(init_GRID_S/(2**(cell_gen+1)), axis=1)\n",
    "\n",
    "    # Select DM particles inside each cell based on cube length generation.\n",
    "    DM_in_cell_IDs = np.asarray(\n",
    "        (np.abs(DM_pos[:,:,0]) < cell_len) & \n",
    "        (np.abs(DM_pos[:,:,1]) < cell_len) & \n",
    "        (np.abs(DM_pos[:,:,2]) < cell_len)\n",
    "    )\n",
    "\n",
    "    # Set DM outside cell to nan values.\n",
    "    DM_pos[~DM_in_cell_IDs] = np.nan\n",
    "\n",
    "    # Sort all nan values to the bottom of axis 1, i.e. the DM-in-cell-X axis \n",
    "    # and truncate array based on DM_lim parameter. This simple way works since \n",
    "    # each cell cannot have more than DM_lim.\n",
    "\n",
    "    ind_2D = DM_pos[:,:,0].argsort(axis=1)\n",
    "    ind_3D = np.repeat(np.expand_dims(ind_2D, axis=2), 3, axis=2)\n",
    "    DM_sort = np.take_along_axis(DM_pos, ind_3D, axis=1)\n",
    "    DM_in = DM_sort[:,:DM_lim,:]\n",
    "    del ind_2D, ind_3D, DM_sort\n",
    "\n",
    "    # Calculate distances of DM and adjust array dimensionally.\n",
    "    DM_dis = np.expand_dims(np.sqrt(np.sum(DM_in**2, axis=2)), axis=2)\n",
    "\n",
    "    # ------------------------------ #\n",
    "    # Calculate short-range gravity. #\n",
    "    # ------------------------------ #\n",
    "\n",
    "    # Offset DM positions by smoothening length of Camila's simulations.\n",
    "    eps = smooth_l / 2.\n",
    "\n",
    "    # nan values to 0 for numerator, and 1 for denominator to avoid infinities.\n",
    "    quot = np.nan_to_num(cell_coords - DM_in, copy=False, nan=0.0) / \\\n",
    "        np.nan_to_num(\n",
    "            np.power((DM_dis**2 + eps**2), 3./2.), copy=False, nan=1.0\n",
    "        )\n",
    "    del DM_in, DM_dis\n",
    "    derivative= G*DM_sim_mass*np.sum(quot, axis=1)\n",
    "    del quot\n",
    "    \n",
    "    # note: Minus sign, s.t. velocity changes correctly (see GoodNotes).\n",
    "    dPsi_short = np.asarray(-derivative, dtype=np.float64)\n",
    "    np.save(f'{out_dir}/dPsi_grid_{fname}_short_range.npy', dPsi_short)\n",
    "\n",
    "\n",
    "def cell_gravity_long_range(\n",
    "    c_id, b_id, cellX_coords, \n",
    "    DM_count, cell_com, \n",
    "    DM_sim_mass, smooth_l, out_dir\n",
    "):\n",
    "\n",
    "    # Distances between cell centers and cell c.o.m. coords.\n",
    "    com_dis = np.expand_dims(\n",
    "        np.sqrt(np.sum((cellX_coords-cell_com)**2, axis=1)), axis=1\n",
    "    )\n",
    "\n",
    "    # Offset DM positions by smoothening length of Camila's simulations.\n",
    "    eps = smooth_l / 2.\n",
    "\n",
    "    # Long-range gravity component for each cell (without including itself).\n",
    "    quot = (cellX_coords-cell_com)/np.power((com_dis**2 + eps**2), 3./2.)\n",
    "    DM_count_sync = np.expand_dims(DM_count, axis=1)\n",
    "    del com_dis\n",
    "\n",
    "    # note: Minus sign, s.t. velocity changes correctly (see GoodNotes).\n",
    "    derivative = -G*DM_sim_mass*np.sum(DM_count_sync*quot, axis=0)\n",
    "    \n",
    "    # Memory peak checks.\n",
    "    # print(derivative.shape, quot.shape, DM_count_sync.shape)\n",
    "    # mem_inc = gso(derivative)+gso(quot)+gso(DM_count_sync)\n",
    "    # print(mem_inc/1e6)\n",
    "    \n",
    "    del quot, DM_count_sync\n",
    "    np.save(f'{out_dir}/cell{c_id}_batch{b_id}_long_range.npy', derivative)\n",
    "\n",
    "\n",
    "\n",
    "def chunksize_long_range(cells, core_mem_MB):\n",
    "    \n",
    "    # Peak memory after calculation of derivative.\n",
    "\n",
    "    itemsize = 8                     # 8 bytes for standard np.float64\n",
    "    mem1 = 3*itemsize                # for derivative\n",
    "    mem2 = cells*3*itemsize          # for quot\n",
    "    mem3 = cells*itemsize            # for DM_count_sync\n",
    "    mem_MB = (mem1+mem2+mem3)/1.e6\n",
    "\n",
    "    batches = 1\n",
    "    while mem_MB >= 0.95*core_mem_MB:\n",
    "        mem_MB *= batches\n",
    "        batches += 1\n",
    "        mem_MB /= batches\n",
    "\n",
    "    chunksize = math.ceil(cells/batches)\n",
    "\n",
    "    return chunksize\n",
    "\n",
    "\n",
    "def batch_generators_long_range(\n",
    "    cell_coords, com_coords, DM_counts,\n",
    "    chunksize \n",
    "):\n",
    "    cells = len(cell_coords)\n",
    "    cell_nums = np.arange(cells)\n",
    "\n",
    "    batches = math.ceil(cells/chunksize)\n",
    "\n",
    "    # Arrays used for naming files.\n",
    "    id_arr = np.array([idx+1 for idx in cell_nums for _ in range(batches)])\n",
    "    batch_arr = np.array([b+1 for _ in cell_nums for b in range(batches)])\n",
    "\n",
    "    # Coord of cell, for which long-range gravity gets calculated.\n",
    "    coord_arr = np.array([cc for cc in cell_coords for _ in range(batches)])\n",
    "\n",
    "    # Chunks for DM_count array, as a generator for all cells.\n",
    "    count_gens = (c for _ in cell_nums for c in chunks(chunksize, DM_counts))\n",
    "    count_chain = chain(gen for gen in count_gens)\n",
    "\n",
    "    # Chunks for cell_com array, as a generator for all cells.\n",
    "    com_gens = (c for _ in cell_nums for c in chunks(chunksize, com_coords))\n",
    "    com_chain = chain(gen for gen in com_gens)\n",
    "\n",
    "    return id_arr, batch_arr, coord_arr, count_chain, com_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99205, 1, 3) (99205,) (99205, 3) (99205, 3)\n",
      "(3,) (99205, 3) (99205, 1)\n",
      "2.381312\n"
     ]
    }
   ],
   "source": [
    "# Load files from cell division.\n",
    "fin_grid = np.load(f'{TEMP_DIR}/fin_grid_{IDname}.npy')\n",
    "DM_count = np.load(f'{TEMP_DIR}/DM_count_{IDname}.npy')\n",
    "cell_com = np.load(f'{TEMP_DIR}/cell_com_{IDname}.npy')\n",
    "\n",
    "new_grid = np.squeeze(fin_grid, axis=1)\n",
    "\n",
    "print(fin_grid.shape, DM_count.shape, cell_com.shape, new_grid.shape)\n",
    "cells = len(new_grid)\n",
    "\n",
    "# Calculate available memory per core.\n",
    "mem_so_far = (psutil.virtual_memory().used - OS_MEM)/MB_UNIT\n",
    "mem_left = 224*1e3 - mem_so_far\n",
    "core_mem_MB = mem_left / psutil.cpu_count()\n",
    "\n",
    "chunksize_lr = chunksize_long_range(cells, core_mem_MB)\n",
    "ids, batches, coords, count_chain, com_chain = batch_generators_long_range(\n",
    "    new_grid, cell_com, DM_count, chunksize_lr\n",
    ")\n",
    "\n",
    "\n",
    "# Memory profile the long-range gravity function.\n",
    "in1 = ids[0]\n",
    "in2 = batches[0]\n",
    "in3 = coords[0]\n",
    "in4 = next(count_chain)\n",
    "in5 = next(com_chain)\n",
    "\n",
    "cell_gravity_long_range(\n",
    "    in1,in2,in3,in4,in5,PRE.DM_SIM_MASS,PRE.SMOOTH_L,TEMP_DIR\n",
    ")\n",
    "\n",
    "# Pass arrays and chains of generators to multiprocessing routine.\n",
    "# with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "#     ex.map(\n",
    "#         cell_gravity_long_range, ids, batches, \n",
    "#         coords, count_chain, com_chain,\n",
    "#         repeat(PRE.DM_SIM_MASS), repeat(PRE.SMOOTH_L), repeat(TEMP_DIR)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dPsi_cells = []\n",
    "\n",
    "def load_dPsi(c_id, batches):\n",
    "    \n",
    "    # Load all batches for current cell.\n",
    "    dPsi_raw = np.array(\n",
    "        [np.load(f'{TEMP_DIR}/cell{c_id}_batch{b}_long_range.npy') for b in batches]\n",
    "    )\n",
    "\n",
    "    # Delete entry, which corresponds to current cell. That \"in-cell\" gravity \n",
    "    # is calculated more precisely with the short-range gravity function.\n",
    "    dPsi_cell_i = np.sum(np.delete(dPsi_raw, c_id-1, axis=0), axis=0)\n",
    "    np.save(f'{TEMP_DIR}/cell{c_id}_long_range.npy', dPsi_cell_i)    \n",
    "\n",
    "\n",
    "# Pass arrays and chains of generators to multiprocessing routine.\n",
    "with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "    ex.map(load_dPsi, ids, repeat(batches))\n",
    "\n",
    "# Save long-range gravity (a [x,y,z] array) for all cells.\n",
    "dPsi_cells = [np.load(f'{TEMP_DIR}/cell{c}_long_range.npy') for c in ids]\n",
    "np.save(f'{TEMP_DIR}/dPsi_grid_{IDname}.npy', np.array(dPsi_cells))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
