{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239.80385546875\n",
      "14.04488671875\n",
      "225.75896875\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "GB_UNIT = 1000*1024**2\n",
    "\n",
    "mem_free = psutil.virtual_memory().available\n",
    "mem_used = psutil.virtual_memory().used\n",
    "print(mem_free/GB_UNIT)\n",
    "print(mem_used/GB_UNIT)\n",
    "print((mem_free-mem_used)/GB_UNIT)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.preface import *\n",
    "import shared.functions as fct\n",
    "\n",
    "# Initialize parameters and files.\n",
    "PRE = PRE(\n",
    "    sim='L025N752', \n",
    "    z0_snap=36, z4_snap=13, DM_lim=1000,\n",
    "    sim_dir=SIM_ROOT, sim_ver=SIM_TYPE,\n",
    "    phis=20, thetas=20, vels=200,\n",
    "    pre_CPUs=10, sim_CPUs=128\n",
    ")\n",
    "\n",
    "\n",
    "TEMP_DIR = f'X_tests'\n",
    "\n",
    "Testing = False\n",
    "if Testing:\n",
    "    mass_gauge = 12.3\n",
    "    mass_range = 0.3\n",
    "    size = 1\n",
    "else:\n",
    "    mass_gauge = 12.0\n",
    "    mass_range = 0.6\n",
    "    size = 10\n",
    "\n",
    "hname = f'1e+{mass_gauge}_pm{mass_range}Msun'\n",
    "fct.halo_batch_indices(\n",
    "    PRE.Z0_STR, mass_gauge, mass_range, 'halos', size, \n",
    "    hname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "halo_batch_IDs = np.load(f'{TEMP_DIR}/halo_batch_{hname}_indices.npy')\n",
    "halo_batch_params = np.load(f'{TEMP_DIR}/halo_batch_{hname}_params.npy')\n",
    "halo_num = len(halo_batch_params)\n",
    "\n",
    "print('********Number density band********')\n",
    "print('Halo batch params (Rvir,Mvir,cNFW):')\n",
    "print(halo_batch_params)\n",
    "print('***********************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================== #\n",
    "# Run precalculations for selected halo in batch. #\n",
    "# =============================================== #\n",
    "\n",
    "halo_j = 2\n",
    "halo_ID = halo_batch_IDs[halo_j]\n",
    "\n",
    "# Generate progenitor index array for current halo.\n",
    "splits = re.split('/', SIM_TYPE)\n",
    "MTname = f'{PRE.SIM}_{splits[0]}_{splits[1]}'\n",
    "proj_IDs = fct.read_MergerTree(PRE.OUT_DIR, MTname, halo_ID)\n",
    "\n",
    "# Create empty arrays to save specifics of each loop.\n",
    "save_GRID_L = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "save_num_DM = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "save_DM_com = []\n",
    "\n",
    "# for j, (snap, proj_ID) in enumerate(zip(\n",
    "#     PRE.NUMS_SNAPS[::-1], proj_IDs\n",
    "# )):\n",
    "\n",
    "j = 0\n",
    "snap = PRE.NUMS_SNAPS[::-1][0]\n",
    "proj_ID = proj_IDs[0]\n",
    "\n",
    "proj_ID = int(proj_ID)\n",
    "\n",
    "# Output halo progress.\n",
    "print(f'halo {halo_j+1}/{halo_num} ; snapshot {snap}')\n",
    "\n",
    "\n",
    "# --------------------------- #\n",
    "# Read and load DM positions. #\n",
    "# --------------------------- #\n",
    "\n",
    "# Define how many shells are used, out of len(DM_SHELL_EDGES)-1.\n",
    "shells = 1\n",
    "DM_shell_edges = DM_SHELL_EDGES[:shells+1]\n",
    "\n",
    "IDname = f'origID{halo_ID}_snap_{snap}'\n",
    "fct.read_DM_all_inRange(\n",
    "    snap, proj_ID, DM_shell_edges, IDname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "\n",
    "# Load DM from all used shells.\n",
    "DM_pre = []\n",
    "for si in range(shells):\n",
    "    DM_pre.append(np.load(f'{TEMP_DIR}/DM_pos_{IDname}_shell{si}.npy'))\n",
    "DM_raw = np.array(list(chain.from_iterable(DM_pre)))\n",
    "del DM_pre\n",
    "\n",
    "# Save c.o.m. coord of all DM particles (for outside_gravity fct.).\n",
    "save_DM_com.append(np.sum(DM_raw, axis=0)/len(DM_raw))\n",
    "\n",
    "# ---------------------- #\n",
    "# Cell division process. #\n",
    "# ---------------------- #\n",
    "\n",
    "# Initialize grid.\n",
    "snap_GRID_L = (int(np.abs(DM_raw).max()) + 1)*kpc\n",
    "raw_grid = fct.grid_3D(snap_GRID_L, snap_GRID_L)\n",
    "init_grid = np.expand_dims(raw_grid, axis=1)\n",
    "\n",
    "# Prepare arrays for cell division.\n",
    "DM_raw *= kpc\n",
    "DM_pos = np.expand_dims(DM_raw, axis=0)\n",
    "DM_pos_for_cell_division = np.repeat(DM_pos, len(init_grid), axis=0)\n",
    "\n",
    "# Cell division.\n",
    "cell_division_count = fct.cell_division(\n",
    "    init_grid, DM_pos_for_cell_division, snap_GRID_L, PRE.DM_LIM, None, TEMP_DIR, IDname\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_gravity_short_range(\n",
    "    cell_coords, cell_gen, init_GRID_S,\n",
    "    DM_pos, DM_lim, DM_sim_mass, smooth_l,\n",
    "    out_dir, fname\n",
    "):\n",
    "    # Center all DM positions w.r.t. cell center.\n",
    "    DM_pos -= cell_coords\n",
    "\n",
    "    # Cell lengths to limit DM particles. Limit for the largest cell is \n",
    "    # GRID_S/2, not just GRID_S, therefore the cell_gen+1 !\n",
    "    cell_len = np.expand_dims(init_GRID_S/(2**(cell_gen+1)), axis=1)\n",
    "\n",
    "    # Select DM particles inside each cell based on cube length generation.\n",
    "    DM_in_cell_IDs = np.asarray(\n",
    "        (np.abs(DM_pos[:,:,0]) < cell_len) & \n",
    "        (np.abs(DM_pos[:,:,1]) < cell_len) & \n",
    "        (np.abs(DM_pos[:,:,2]) < cell_len)\n",
    "    )\n",
    "\n",
    "    # Set DM outside cell to nan values.\n",
    "    DM_pos[~DM_in_cell_IDs] = np.nan\n",
    "\n",
    "    # Sort all nan values to the bottom of axis 1, i.e. the DM-in-cell-X axis \n",
    "    # and truncate array based on DM_lim parameter. This simple way works since \n",
    "    # each cell cannot have more than DM_lim.\n",
    "\n",
    "    ind_2D = DM_pos[:,:,0].argsort(axis=1)\n",
    "    ind_3D = np.repeat(np.expand_dims(ind_2D, axis=2), 3, axis=2)\n",
    "    DM_sort = np.take_along_axis(DM_pos, ind_3D, axis=1)\n",
    "    DM_in = DM_sort[:,:DM_lim,:]\n",
    "    del ind_2D, ind_3D, DM_sort\n",
    "\n",
    "    # Calculate distances of DM and adjust array dimensionally.\n",
    "    DM_dis = np.expand_dims(np.sqrt(np.sum(DM_in**2, axis=2)), axis=2)\n",
    "\n",
    "    # ------------------------------ #\n",
    "    # Calculate short-range gravity. #\n",
    "    # ------------------------------ #\n",
    "\n",
    "    # Offset DM positions by smoothening length of Camila's simulations.\n",
    "    eps = smooth_l / 2.\n",
    "\n",
    "    # nan values to 0 for numerator, and 1 for denominator to avoid infinities.\n",
    "    quot = np.nan_to_num(cell_coords - DM_in, copy=False, nan=0.0) / \\\n",
    "        np.nan_to_num(\n",
    "            np.power((DM_dis**2 + eps**2), 3./2.), copy=False, nan=1.0\n",
    "        )\n",
    "    del DM_in, DM_dis\n",
    "    derivative= G*DM_sim_mass*np.sum(quot, axis=1)\n",
    "    del quot\n",
    "    \n",
    "    # note: Minus sign, s.t. velocity changes correctly (see GoodNotes).\n",
    "    dPsi_short = np.asarray(-derivative, dtype=np.float64)\n",
    "    np.save(f'{out_dir}/dPsi_grid_{fname}_short_range.npy', dPsi_short)\n",
    "\n",
    "\n",
    "def cell_gravity_long_range(\n",
    "    c_id, b_id, cellX_coords, \n",
    "    DM_count, cell_com, \n",
    "    DM_sim_mass, smooth_l, out_dir\n",
    "):\n",
    "\n",
    "    # Distances between cell centers and cell c.o.m. coords.\n",
    "    com_dis = np.sqrt(np.sum((cellX_coords-cell_com)**2, axis=1))\n",
    "\n",
    "    # Adjust dimensionally for later division.\n",
    "    com_dis_sync = np.expand_dims(com_dis, axis=1)\n",
    "\n",
    "\n",
    "    # Offset DM positions by smoothening length of Camila's simulations.\n",
    "    eps = smooth_l / 2.\n",
    "\n",
    "    # Long-range gravity component for each cell (without including itself).\n",
    "    quot = (cellX_coords-cell_com)/np.power((com_dis_sync**2 + eps**2), 3./2.)\n",
    "    DM_count_sync = np.expand_dims(DM_count, axis=1)\n",
    "    derivative = G*DM_sim_mass*np.sum(DM_count_sync*quot, axis=0)\n",
    "    del quot\n",
    "\n",
    "    # note: Minus sign, s.t. velocity changes correctly (see GoodNotes).\n",
    "    dPsi_long = np.asarray(-derivative, dtype=np.float64)\n",
    "    np.save(f'{out_dir}/cell{c_id}_batch{b_id}_long_range.npy', dPsi_long)\n",
    "\n",
    "\n",
    "def batch_generators_long_range(\n",
    "    cell_coords, com_coords, DM_counts,\n",
    "    chunk_size \n",
    "):\n",
    "    cells = len(cell_coords)\n",
    "    cell_nums = np.arange(cells)\n",
    "\n",
    "    num = math.ceil(cells/chunk_size)\n",
    "\n",
    "    # Arrays used for naming files.\n",
    "    id_arr = np.array([idx+1 for idx in cell_nums for _ in range(num)])\n",
    "    batch_arr = np.array([b+1 for _ in cell_nums for b in range(num)])\n",
    "\n",
    "    # Coord of cell, for which long-range gravity gets calculated.\n",
    "    coord_arr = np.array([cc for cc in cell_coords for _ in range(num)])\n",
    "\n",
    "    # Chunks for DM_count array, as a generator for all cells.\n",
    "    count_gens = (c for _ in cell_nums for c in chunks(chunk_size, DM_counts))\n",
    "    count_chain = chain(gen for gen in count_gens)\n",
    "\n",
    "    # Chunks for cell_com array, as a generator for all cells.\n",
    "    com_gens = (c for _ in cell_nums for c in chunks(chunk_size, com_coords))\n",
    "    com_chain = chain(gen for gen in com_gens)\n",
    "\n",
    "    return id_arr, batch_arr, coord_arr, count_chain, com_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files from cell division.\n",
    "fin_grid = np.load(f'{TEMP_DIR}/fin_grid_{IDname}.npy')\n",
    "DM_count = np.load(f'{TEMP_DIR}/DM_count_{IDname}.npy')\n",
    "cell_com = np.load(f'{TEMP_DIR}/cell_com_{IDname}.npy')\n",
    "\n",
    "new_grid = np.squeeze(fin_grid, axis=1)\n",
    "\n",
    "print(fin_grid.shape, DM_count.shape, cell_com.shape, new_grid.shape)\n",
    "\n",
    "test_chunk_size = len(new_grid)\n",
    "ids, batches, coords, count_chain, com_chain = batch_generators_long_range(\n",
    "    new_grid, cell_com, DM_count, test_chunk_size\n",
    ")\n",
    "\n",
    "# Check memory.\n",
    "mem_free = psutil.virtual_memory().available\n",
    "mem_used = psutil.virtual_memory().used\n",
    "cores = psutil.cpu_count()\n",
    "print(mem_free/GB_UNIT)\n",
    "print(mem_used/GB_UNIT)\n",
    "\n",
    "\n",
    "# Pass arrays and chains of generators to multiprocessing routine.\n",
    "with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "    ex.map(\n",
    "        cell_gravity_long_range, ids, batches, \n",
    "        coords, count_chain, com_chain,\n",
    "        repeat(PRE.DM_SIM_MASS), repeat(PRE.SMOOTH_L), repeat(TEMP_DIR)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dPsi_cells = []\n",
    "\n",
    "def load_dPsi(c_id, batches):\n",
    "    \n",
    "    # Load all batches for current cell.\n",
    "    dPsi_raw = np.array(\n",
    "        [np.load(f'{TEMP_DIR}/cell{c_id}_batch{b}_long_range.npy') for b in batches]\n",
    "    )\n",
    "\n",
    "    # Delete entry, which corresponds to current cell. That \"in-cell\" gravity \n",
    "    # is calculated more precisely with the short-range gravity function.\n",
    "    dPsi_cell_i = np.sum(np.delete(dPsi_raw, c_id-1, axis=0), axis=0)\n",
    "    np.save(f'{TEMP_DIR}/cell{c_id}_long_range.npy', dPsi_cell_i)    \n",
    "\n",
    "\n",
    "# Pass arrays and chains of generators to multiprocessing routine.\n",
    "with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "    ex.map(load_dPsi, ids, repeat(batches))\n",
    "\n",
    "# Save long-range gravity (a [x,y,z] array) for all cells.\n",
    "dPsi_cells = [np.load(f'{TEMP_DIR}/cell{c}_long_range.npy') for c in ids]\n",
    "np.save(f'{TEMP_DIR}/dPsi_grid_{IDname}.npy', np.array(dPsi_cells))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
