{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.preface import *\n",
    "import shared.functions as fct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch. 0: Preliminary Investigations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D grid, center coord. pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_2D(l, s):\n",
    "\n",
    "    # 2D spatial grid, discretized.\n",
    "    eps = s/10\n",
    "    x, y = np.mgrid[-l:l+eps:s, -l:l+eps:s]\n",
    "\n",
    "    # [x y] edge coordinate pairs of above grid.\n",
    "    xy = np.mgrid[-l:l+eps:s, -l:l+eps:s].reshape(2,-1).T\n",
    "\n",
    "    # Create center coord.-pairs.\n",
    "    x_centers = (x[1:,:] + x[:-1,:])/2.\n",
    "    y_centers = (y[:,1:] + y[:,:-1])/2.\n",
    "    centers = np.array([x_centers[:,:-1], y_centers[:-1,:]])\n",
    "    cent_coordPairs2D = centers.reshape(2,-1).T\n",
    "    print('All coord. pairs 2D:\\n', cent_coordPairs2D)\n",
    "    # print('Coord pairs 2D shape:', cent_coordPairs2D.shape)\n",
    "\n",
    "    return cent_coordPairs2D\n",
    "\n",
    "limit_coarse, space_coarse = 1.5, 1.\n",
    "cent_coordPairs2D = grid_2D(limit_coarse, space_coarse)\n",
    "\n",
    "# Delete middle square.\n",
    "cent_coordPairs2D = np.delete(cent_coordPairs2D, 4, axis=0)\n",
    "\n",
    "# Create finegrained square.\n",
    "limit_fine, space_fine = limit_coarse/2., space_coarse/2.\n",
    "cent_coordPairs2D_fine = grid_2D(limit_fine, space_fine)\n",
    "\n",
    "# Insert finegrained square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D grid, center coord. pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D spatial grid, discretized.\n",
    "x, y, z = np.mgrid[-1:1.1:1., -1:1.1:1., -1:1.1:1.]\n",
    "# print(x[0,...], x.shape)\n",
    "\n",
    "x_centers = (x[1:,...] + x[:-1,...])/2.\n",
    "# print(x_centers, x_centers.shape)\n",
    "\n",
    "y_centers = (y[:,1:,:] + y[:,:-1,:])/2.\n",
    "# print(y_centers, y_centers.shape)\n",
    "\n",
    "z_centers = (z[...,1:] + z[...,:-1])/2.\n",
    "# print(z_centers, z_centers.shape)\n",
    "\n",
    "\n",
    "# Create center coord.-pairs., truncate redundant points.\n",
    "centers3D = np.array([\n",
    "    x_centers[:,:-1,:-1], \n",
    "    y_centers[:-1,:,:-1], \n",
    "    z_centers[:-1,:-1,:]\n",
    "])\n",
    "# print(centers3D, centers3D.shape)\n",
    "\n",
    "cent_coordPairs3D = centers3D.reshape(3,-1).T \n",
    "print(cent_coordPairs3D, cent_coordPairs3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch. 1: Milky Way-type halo and simple grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D plot of the DM particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DM particles.\n",
    "fct.read_DM_positions_randomHalo(which_halos='halos', mass_select=12)\n",
    "\n",
    "# Build grid around Milky Way.\n",
    "MW_grid = fct.grid_3D(GRID_L, GRID_S) / kpc\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Read in DM particle positions.\n",
    "DM_pos = np.load('sim_data/DM_positions_halos_M12.npy')\n",
    "print(f'{len(DM_pos)}')\n",
    "x_DM, y_DM, z_DM = DM_pos[:,0], DM_pos[:,1], DM_pos[:,2]\n",
    "cut = 10\n",
    "x, y, z = x_DM[1::cut], y_DM[1::cut], z_DM[1::cut]\n",
    "\n",
    "ax.scatter(x, y, z, alpha=0.1, c='dodgerblue')\n",
    "\n",
    "# Draw sphere around GC with radius=Rvir_MW.\n",
    "rGC = Rvir_MW/kpc\n",
    "uGC, vGC = np.mgrid[0:2 * np.pi:200j, 0:np.pi:100j]\n",
    "xGC = rGC * np.cos(uGC) * np.sin(vGC)\n",
    "yGC = rGC * np.sin(uGC) * np.sin(vGC)\n",
    "zGC = rGC * np.cos(vGC)\n",
    "\n",
    "xg, yg, zg = MW_grid[:,0], MW_grid[:,1], MW_grid[:,2] \n",
    "ax.scatter(xg, yg, zg, s=0.2, marker='x', color='black', alpha=0.5)\n",
    "\n",
    "\n",
    "ax.plot_surface(\n",
    "    xGC, yGC, zGC, alpha=0.1, \n",
    "    cmap=plt.cm.coolwarm, vmin=-1, vmax=1,# antialiased=False,\n",
    "    rstride=1, cstride=1\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate gravity in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_pos = np.load('sim_data/DM_positions_halos_M12.npy')\n",
    "\n",
    "### Testing 1 cell with coords. at earth.\n",
    "cell_id = 0\n",
    "cell1 = np.array([8.5, 0, 0])*kpc\n",
    "\n",
    "cell_vector = fct.cell_gravity(cell1, DM_pos, GRAV_RANGE, DM_SIM_MASS)\n",
    "cell_vector /= (kpc/s**2)  \n",
    "print(cell_vector)\n",
    "print(np.sqrt(np.sum(cell_vector**2)))\n",
    "\n",
    "#! this should be around same order of magnitude as in spher. symmetric setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch. 2: Broadcasting for cell_gravity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct.read_DM_positions_randomHalo(which_halos='halos', mass_select=12)\n",
    "DM = np.load('sim_data/DM_positions_halos_M12.npy')[1::10]\n",
    "grid = fct.grid_3D(GRID_L, GRID_S)\n",
    "\n",
    "grid = np.expand_dims(grid, axis=1)\n",
    "\n",
    "DM = np.expand_dims(DM, axis=0)\n",
    "DM = np.repeat(DM, len(grid), axis=0)\n",
    "print('DM positions array shape', DM.shape)\n",
    "\n",
    "# diff = DM - grid\n",
    "# print(diff.shape, (diff.nbytes)/1e6)\n",
    "\n",
    "fct.cell_gravity_3D(grid, DM, GRAV_RANGE, DM_SIM_MASS)\n",
    "dPsi_grid = np.load('CubeSpace/dPsi_grid_snapsnot_X.npy')\n",
    "dPsi_grid /= (kpc/s**2) \n",
    "mags = np.sqrt(np.sum(dPsi_grid**2, axis=1))\n",
    "print(mags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch. 3: Combined precalculations for all snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.preface import *\n",
    "import shared.functions as fct\n",
    "\n",
    "for i in range(12,37):\n",
    "    snap_i = f'{i:04d}'\n",
    "    print(snap_i)\n",
    "\n",
    "    # 1. Read in DM positions of halo in snapshot.\n",
    "    fct.read_DM_positions_randomHalo(\n",
    "        which_halos='halos', mass_select=12, mass_range=1., snap_num=snap_i\n",
    "        )\n",
    "    DM_pos = np.load('sim_data/DM_positions_halos_M12.npy')[1::10]\n",
    "\n",
    "    # 2. Build the spatial grid, depending on virial radius of halo, etc.\n",
    "    cell_grid = fct.grid_3D(GRID_L, GRID_S)\n",
    "    np.save(f'CubeSpace/cell_grid_snapsnot_{snap_i}', cell_grid)\n",
    "    cell_grid = np.expand_dims(cell_grid, axis=1)\n",
    "\n",
    "    # 2.5 Adjust arrays.\n",
    "    DM_pos = np.expand_dims(DM_pos, axis=0)\n",
    "    DM_pos = np.repeat(DM_pos, len(cell_grid), axis=0)\n",
    "\n",
    "    # 3. Calculate derivatives of each cell.\n",
    "    fct.cell_gravity_3D(\n",
    "        cell_grid, DM_pos, GRAV_RANGE, DM_SIM_MASS, snap_num=snap_i\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snapshot_0012 is at redshift ~3.8.\n",
    "\n",
    "**BUT** it contains no halo of mass_select=12 anymore.\n",
    "\n",
    "**TODO:** start at snapshot_0036 (z~1e-16) and **trace same halo** backwards through the\n",
    "snapshots.\n",
    "\n",
    "Ugly fix for now: Extended mass_select window to search down to 1e11*Msun halos.\n",
    "Then just pick random halo, will not be the same in all snapshots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift z of each snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeds = np.zeros(25)\n",
    "nums = []\n",
    "for j, i in enumerate(range(12,37)):\n",
    "    snap_i = f'{i:04d}'\n",
    "    nums.append(snap_i)\n",
    "\n",
    "    with h5py.File(f'{SIM_DATA}/snapshot_{snap_i}.hdf5') as snap:\n",
    "        zeds[j] = snap['Cosmology'].attrs['Redshift'][0]\n",
    "\n",
    "np.save(f'shared/ZEDS_SNAPSHOTS.npy', np.asarray(zeds))\n",
    "np.save(f'shared/NUMS_SNAPSHOTS.npy', np.asarray(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch. 4: Better derivative grid structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final function: compile everything here later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/fabian/my_github_projects/neutrino_clustering_V2/CubeSpace.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabian/my_github_projects/neutrino_clustering_V2/CubeSpace.ipynb#ch0000020?line=50'>51</a>\u001b[0m fw_diff \u001b[39m=\u001b[39m row[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m row[\u001b[39m1\u001b[39m:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabian/my_github_projects/neutrino_clustering_V2/CubeSpace.ipynb#ch0000020?line=51'>52</a>\u001b[0m max_DM_rows_no_last_cell \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margwhere(fw_diff\u001b[39m.\u001b[39mflatten() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/fabian/my_github_projects/neutrino_clustering_V2/CubeSpace.ipynb#ch0000020?line=52'>53</a>\u001b[0m max_DM_rows \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack((DM_IDs[max_DM_rows_no_last_cell,:], DM_IDs[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,:]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabian/my_github_projects/neutrino_clustering_V2/CubeSpace.ipynb#ch0000020?line=54'>55</a>\u001b[0m \u001b[39m# Replace all entries beyond these indices (for each cell) with nan values.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/fabian/my_github_projects/neutrino_clustering_V2/CubeSpace.ipynb#ch0000020?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cell_num):\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "cell_num, DM_num = 5, 8\n",
    "DM_lim = 2\n",
    "DM_range = 5\n",
    "init_cc = np.arange(cell_num*3).reshape((cell_num, 1, 3))\n",
    "DM_pos = np.random.random(size=(cell_num, DM_num, 3)) * 5\n",
    "\n",
    "# def cell_division(init_cc, DM_pos, DM_range, DM_lim):\n",
    "\n",
    "\"\"\"\n",
    "Algorithm for fine-graining a given initial (uniform and rough) grid, which contains the coords of the center of the cells.\n",
    "Given a DM particle count threshold, the cells containing an amount of DM above this threshold will be divided into 8 new cells. This process is repeated until each cell is below the threshold. \n",
    "The end result is a grid of cell (center) coordinates, which is adjusted to the given DM particle distribution.\n",
    "\"\"\"\n",
    "\n",
    "# Reshape input arrays for compatibility.\n",
    "# init_cc = np.expand_dims(init_cc, axis=1)\n",
    "\n",
    "# --------------------------------------------------------------------- #\n",
    "# Determine which cells have DM above threshold and thus need division. #\n",
    "# --------------------------------------------------------------------- #\n",
    "\n",
    "# Center all DM positions w.r.t. center, for all cells.\n",
    "DM_cc = DM_pos*kpc - init_cc\n",
    "\n",
    "# Calculate distances of all DM to center, for all cells.\n",
    "DM_dist = np.sqrt(np.sum(DM_cc**2, axis=2))\n",
    "\n",
    "# Indices to order other arrays according to DM dist in ascending order.\n",
    "ind = DM_dist.argsort(axis=1)\n",
    "\n",
    "# Reshape these indices for compatibility.\n",
    "ind_3D = np.expand_dims(ind, axis=2)\n",
    "ind_3D = np.repeat(ind_3D, 3, axis=2)\n",
    "\n",
    "# Sort DM arrays according to DM distance with these indices.\n",
    "DM_cc_sort = np.take_along_axis(DM_cc, ind_3D, axis=1)\n",
    "DM_dist_sort = np.take_along_axis(DM_dist, ind, axis=1)\n",
    "\n",
    "# This array is a bit confusing: It has the shape (X,2) and contains pairs \n",
    "# of indices, where the 1st entry is the cell number and the 2nd the index \n",
    "# of a DM particle inside the given range for that cell. X is then an \n",
    "# arbitrary number, which counts all DM particles inside range across all \n",
    "# cells.\n",
    "DM_IDs = np.argwhere(DM_dist_sort <= DM_range)\n",
    "\n",
    "# Find the index unique to each cell, up to which the DM particles should\n",
    "# be kept, while the rest is outside range and no longer relevant.\n",
    "# Due to the method chosen, the last cell is not included and is attached \n",
    "# seperately with np.vstack(...).\n",
    "row = DM_IDs.T[1]\n",
    "fw_diff = row[:-1] - row[1:]\n",
    "max_DM_rows_no_last_cell = np.argwhere(fw_diff.flatten() >= 0).flatten()\n",
    "max_DM_rows = np.vstack((DM_IDs[max_DM_rows_no_last_cell,:], DM_IDs[-1,:]))\n",
    "\n",
    "# Replace all entries beyond these indices (for each cell) with nan values.\n",
    "for i in range(cell_num):\n",
    "    DM_cc_sort[i, max_DM_IDs[i,1]+1:, :] = np.nan\n",
    "\n",
    "#! potential bug?: some case not covered, where one cell does not get a \n",
    "#! selection index...\n",
    "#! run until you see error?\n",
    "\n",
    "# Drop \"rows\" common to all cells, which contain only nan values. This \n",
    "# \"maximum row\" is determined by the highest value in the array, which \n",
    "# contains the index of the row for each cell, beyond which the values are \n",
    "# replaced by nan values.\n",
    "max_DM_rank = np.max(max_DM_rows[:,1])\n",
    "DM_cc_compact = np.delete(DM_cc_sort, np.s_[max_DM_rank+1:], axis=1)\n",
    "print(DM_cc_compact)\n",
    "\n",
    "# Count the number of DM particles in each cell, after all the filtering.\n",
    "DM_count = np.count_nonzero(~np.isnan(DM_cc_compact[:,:,0]), axis=1)\n",
    "print(DM_count)\n",
    "\n",
    "# Drop all cells containing an amount of DM below the given threshold, \n",
    "# from the DM positions array...\n",
    "cell_cut = DM_count < DM_lim\n",
    "DM_cc_minimal = np.delete(DM_cc_compact, cell_cut, axis=0)\n",
    "print()\n",
    "\n",
    "# ...and the initial cell coordinates grid. This array contains all cells \n",
    "# (i.e. their coords. ), which need to be divided into 8 \"child cells\", \n",
    "# hence the name \"parent cells\".\n",
    "parent_cc = np.delete(init_cc, cell_cut, axis=0)\n",
    "print()\n",
    "\n",
    "# \"Reset\" the DM coords, s.t. all DM positions are w.r.t. the origin of \n",
    "# (0,0,0) again. This way we can easily center them on the new child cells \n",
    "# again, as done in later steps below.\n",
    "DM_cc_reset = DM_cc_minimal + parent_cc\n",
    "print()\n",
    "\n",
    "# ------------------------------------------------ #\n",
    "# Replace each parent cell by the 8 new child cells.\n",
    "# ------------------------------------------------ #\n",
    "\n",
    "# Repeat each DM \"column\" 8 times, so each can get centered on a new cell.\n",
    "DM_raw8 = np.repeat(DM_cc_reset, repeats=8, axis=0)\n",
    "\n",
    "# Create 8 new cells around origin of (0,0,0). The length and size of the \n",
    "# new cells is determined by the previous length of the parent cell.\n",
    "parent_GRID_S = 5\n",
    "sub8 = fct.grid_3D(parent_GRID_S/2., parent_GRID_S/2)\n",
    "\n",
    "# Match dimensions of child-array(s) to parent-array(s).\n",
    "sub8 = np.expand_dims(sub8, axis=0)\n",
    "sub8 = np.repeat(sub8, len(parent_cell_coords), axis=0)\n",
    "\n",
    "# Center child-array(s) on parent cell coords.\n",
    "sub8_coords = sub8 - parent_cell_coords\n",
    "\n",
    "# Reshape array to match repeated DM position array.\n",
    "sub8_coords = np.reshape(sub8_coords, (len(parent_cell_coords)*8, 3))\n",
    "sub8_coords = np.expand_dims(sub8_coords, axis=1)\n",
    "\n",
    "# Center the repeated DM columns on the child cells.\n",
    "DM_sub8_cc = DM_raw8 - sub8_coords\n",
    "print(DM_sub8_cc)\n",
    "\n",
    "# Delete all cells in initial cell coords array, corresponding to the cells in need of division, i.e. the parent cells.\n",
    "cc_no_parents = np.delete(init_cc, ~cell_cut, axis=0)\n",
    "\n",
    "# Concatenate the new child cell coords at the end of the initial cell \n",
    "# coords array, now containing no parent cells. This is now the array with \n",
    "# all cell coords after the division process of this iteration.\n",
    "new_cell_coords = np.concatenate((cc_no_parents, sub8_coords), axis=0)\n",
    "print(new_cell_coords)\n",
    "\n",
    "\n",
    "# cell_num, DM_num = 5, 8\n",
    "# mock_init_cc = np.arange(cell_num*3).reshape((cell_num, 1, 3))\n",
    "# mock_DM_pos = np.random.random(size=(cell_num, DM_num, 3)) * 5\n",
    "# cell_division(\n",
    "#     init_cc  = mock_init_cc, \n",
    "#     DM_pos   = mock_DM_pos, \n",
    "#     DM_lim   = 2, \n",
    "#     DM_range = 5\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps until: DM_pos array (cells, DM_amount, 3) containing nans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random values for DM positions for testing.\n",
    "cell_num, DM_num = 3, 6\n",
    "DM_cc = np.random.random(size=(cell_num, DM_num, 3)) * 5\n",
    "\n",
    "# Calculate distances of DM to cc.\n",
    "DM_dist = np.sqrt(np.sum(DM_cc**2, axis=2))\n",
    "\n",
    "# Ascending order indices.\n",
    "ind = DM_dist.argsort(axis=1)\n",
    "ind_3D = np.expand_dims(ind, axis=2)\n",
    "ind_3D = np.repeat(ind_3D, 3, axis=2)\n",
    "\n",
    "# Sort DM positions according to dist.\n",
    "DM_pos_sort = np.take_along_axis(DM_cc, ind_3D, axis=1)\n",
    "DM_dist_sort = np.take_along_axis(DM_dist, ind, axis=1)\n",
    "\n",
    "print(DM_pos_sort)\n",
    "\n",
    "# Keep DM inside certain range.\n",
    "radius = 5\n",
    "\n",
    "# Index array for DM inside radius, for each cell: \n",
    "# [[cell_num, DM_particle_in_cell],...] (see print)\n",
    "DM_IDs = np.argwhere(DM_dist_sort <= radius)\n",
    "# print('DM_IDs \\n', DM_IDs)\n",
    "\n",
    "# Find index, up to which DM particles should be kept for each cell.\n",
    "row = DM_IDs.T[1]\n",
    "fw_diff = row[:-1] - row[1:]\n",
    "max_DM_rows = np.argwhere(fw_diff.flatten() >= 0).flatten()\n",
    "\n",
    "# -> Index up to max DM particle inside radius, paired with each cell num: \n",
    "# [[cell_0, DM_max_rank_for_cell_1],...] (see print)\n",
    "selection = np.vstack((DM_IDs[max_DM_rows,:], DM_IDs[-1,:]))\n",
    "print(selection, selection.shape)\n",
    "\n",
    "# Replace all entries beyond these indices (for each cell) with nan values.\n",
    "for i in range(cell_num):\n",
    "    DM_pos_sort[i, selection[i,1]+1:, :] = np.nan\n",
    "\n",
    "print(DM_pos_sort)\n",
    "\n",
    "#! bug: some case not covered, where one cell does not get a selection index...\n",
    "#!      run cell until you see error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps until: deleting common nan rows, and cells not containing enough DM, and resetting DM positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all \"rows\", shared by all cells, which have only nan values,\n",
    "# determined by maximum present value in DM rank of all cells.\n",
    "\n",
    "# 1. Find max index (for DM rank) present in selection array.\n",
    "max_DM_rank = np.max(selection[:,1])\n",
    "print(max_DM_rank)\n",
    "\n",
    "# 2. \"Delete\" those common rows. \n",
    "DM_cc_compact = np.delete(DM_pos_sort, np.s_[max_DM_rank+1:], axis=1)\n",
    "\n",
    "print(DM_cc_compact)\n",
    "\n",
    "# Counting how many (non-)nan rows are in each cell.\n",
    "DM_particle_count = np.count_nonzero(~np.isnan(DM_cc_compact[:,:,0]), axis=1)\n",
    "nan_count = np.count_nonzero(np.isnan(DM_cc_compact[:,:,0]), axis=1)\n",
    "print(DM_particle_count, nan_count)\n",
    "\n",
    "\n",
    "# Drop all cells, which have DM particle amount lower than threshold.\n",
    "#note: see later which is more efficient, drop cells from DM_compact or before.\n",
    "cells_below_DMthresh = DM_particle_count < 2\n",
    "print(cells_below_DMthresh)\n",
    "\n",
    "DM_cc_cell_filtered = np.delete(DM_cc_compact, cells_below_DMthresh, axis=0)\n",
    "print(DM_cc_cell_filtered)\n",
    "\n",
    "# Also filter the cell coordinates. \n",
    "proxy_cell_coords = np.arange(cell_num*3).reshape((cell_num, 1, 3))\n",
    "parent_cell_coords = np.delete(proxy_cell_coords, cells_below_DMthresh, axis=0)\n",
    "\n",
    "# Reset the DM coords. \n",
    "DM_cc_reset = DM_cc_cell_filtered + parent_cell_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array now contains all cells in need of subdivision, with coords. centered on (0,0,0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps for: creating coord array for sub 8 division of cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat each DM column 8 times, so each can get centered on a new cell.\n",
    "DM_raw8 = np.repeat(DM_cc_reset, repeats=8, axis=0)\n",
    "\n",
    "# Create 8 new cells around (0,0,0). Length and size of new cells determined\n",
    "# by previous length of parent cell.\n",
    "parent_GRID_S = 5\n",
    "sub8 = fct.grid_3D(parent_GRID_S/2., parent_GRID_S/2)\n",
    "\n",
    "# Match dimensions of parent cell coords. array.\n",
    "sub8 = np.expand_dims(sub8, axis=0)\n",
    "sub8 = np.repeat(sub8, len(parent_cell_coords), axis=0)\n",
    "\n",
    "# Center new \"8-batch\" of sub-cells on parent cell coords.\n",
    "sub8_coords = sub8 - parent_cell_coords\n",
    "\n",
    "# Now reshape array to match repeated DM position array.\n",
    "sub8_coords = np.reshape(sub8_coords, (len(parent_cell_coords)*8, 3))\n",
    "sub8_coords = np.expand_dims(sub8_coords, axis=1)\n",
    "\n",
    "# Center the repeated DM columns on the different new sub8 cells.\n",
    "DM_sub8_cc = DM_raw8 - sub8_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### steps for: attaching coords of new cells to \"old\" (previous iteration) cell array, while deleting parent cell entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original thought was: replace parent cells, which underwent division, with the 8 new coordinates. \n",
    "\n",
    "But it doesn't seem necessary: just attach new cell coords at end of old cell_coords array while deleting the parent cell entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Delete all cells in \"original\" cell coords array, corresponing to the cells in need of division (parent cells).\n",
    "cell_coords_no_parents = np.delete(\n",
    "    proxy_cell_coords, ~cells_below_DMthresh, axis=0\n",
    ")\n",
    "\n",
    "# 2. Concatenate the new sub8 cell coords at the end of the cell coords array containing no \"parents\". This is now the array with all cell_coords after the division process.\n",
    "new_cell_coords = np.concatenate((cell_coords_no_parents, sub8_coords), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('NC_numba')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f954fd519baabf9adc4c45dc1841670b54a153fe717f7fe4f74275668c90e9d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
