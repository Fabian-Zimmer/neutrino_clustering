{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healpy parameters: Nside=2, Npix=48, pix_sr=0.2617993877991494\n",
      "********************* Initialization *********************\n",
      "# Initial conditions for neutrinos:\n",
      "PHIs = 48, THETAs=48, Vs=10000\n",
      "Total neutrinos: 23040000\n",
      "# Simulation parameters:\n",
      "Simulation box: L025N752\n",
      "Snapshot from 0036 (z=0) to 0013 (z=4)\n",
      "Pre/Sim CPUs 128/128\n",
      "DM limit for cells: 10000\n",
      "DM mass of sim box in log10 Msun: 6.1577\n",
      "Smoothening length of sim box in kpc: 0.65\n",
      "# File management:\n",
      "Box files directory: \n",
      " /projects/0/einf180/Tango_sims/L025N752/DMONLY/SigmaConstant00\n",
      "Output directory: \n",
      " /gpfs/home4/zimmer/neutrino_clustering_V2/L025N752/DMONLY/SigmaConstant00\n",
      "**********************************************************\n",
      "********Number density band********\n",
      "Halo batch params (Rvir,Mvir,cNFW):\n",
      "[[253.5523526   12.24058042   6.9286026 ]\n",
      " [158.62979351  11.62953177   8.03988676]\n",
      " [137.07912107  11.43929142   9.41292697]]\n",
      "***********************************\n"
     ]
    }
   ],
   "source": [
    "# Save how much memory is used by OS and not available for script.\n",
    "import psutil\n",
    "MB_UNIT = 1024**2\n",
    "OS_MEM = (psutil.virtual_memory().used)\n",
    "\n",
    "from shared.preface import *\n",
    "import shared.functions as fct\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "# Generate (phi, theta) coord. pairs based on desired healpy map.\n",
    "Nside = 2**1              # Specify nside parameter\n",
    "Npix = 12 * Nside**2      # Number of pixels\n",
    "pix_sr = (4*np.pi)/Npix   # Pixel size  [sr]\n",
    "print(f'Healpy parameters: Nside={Nside}, Npix={Npix}, pix_sr={pix_sr}')\n",
    "hp_thetas, hp_phis = np.array(hp.pixelfunc.pix2ang(Nside, np.arange(Npix)))\n",
    "\n",
    "# Initialize parameters and files.\n",
    "PRE = PRE(\n",
    "    sim='L025N752', \n",
    "    z0_snap=36, z4_snap=13, DM_lim=10000,\n",
    "    sim_dir=SIM_ROOT, sim_ver=SIM_TYPE,\n",
    "    phis=hp_phis, thetas=hp_thetas, vels=10000,\n",
    "    pre_CPUs=128, sim_CPUs=128, mem_lim_GB=224\n",
    ")\n",
    "\n",
    "# Make temporary folder to store files, s.t. parallel runs don't clash.\n",
    "rand_code = ''.join(\n",
    "    random.choices(string.ascii_uppercase + string.digits, k=4)\n",
    ")\n",
    "TEMP_DIR = f'{PRE.OUT_DIR}/temp_data_{rand_code}'\n",
    "os.makedirs(TEMP_DIR)\n",
    "\n",
    "# Halo parameters.\n",
    "mass_gauge = 12.0\n",
    "mass_range = 0.6\n",
    "size = 3\n",
    "\n",
    "hname = f'1e+{mass_gauge}_pm{mass_range}Msun'\n",
    "fct.halo_batch_indices(\n",
    "    PRE.Z0_STR, mass_gauge, mass_range, 'halos', size, \n",
    "    hname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "halo_batch_IDs = np.load(f'{TEMP_DIR}/halo_batch_{hname}_indices.npy')\n",
    "halo_batch_params = np.load(f'{TEMP_DIR}/halo_batch_{hname}_params.npy')\n",
    "halo_num = len(halo_batch_params)\n",
    "\n",
    "print('********Number density band********')\n",
    "print('Halo batch params (Rvir,Mvir,cNFW):')\n",
    "print(halo_batch_params)\n",
    "print('***********************************')\n",
    "\n",
    "\n",
    "def EOMs(s_val, y):\n",
    "\n",
    "    # Initialize vector.\n",
    "    x_i, u_i = np.reshape(y, (2,3))\n",
    "\n",
    "    # Switch to \"numerical reality\" here.\n",
    "    x_i *= kpc\n",
    "    u_i *= (kpc/s)\n",
    "\n",
    "    # Find z corresponding to s via interpolation.\n",
    "    z = np.interp(s_val, S_STEPS, ZEDS)\n",
    "\n",
    "    # Snapshot specific parameters.\n",
    "    idx = np.abs(PRE.ZEDS_SNAPS - z).argmin()\n",
    "    snap = PRE.NUMS_SNAPS[idx]\n",
    "    snap_GRID_L = snaps_GRID_L[idx]\n",
    "\n",
    "    # Neutrino inside cell grid.\n",
    "    if np.all(np.abs(x_i)) <= snap_GRID_L:\n",
    "\n",
    "        # Find which (pre-calculated) derivative grid to use at current z.\n",
    "        simname = f'origID{halo_ID}_snap_{snap}'\n",
    "        dPsi_grid = fct.load_grid(TEMP_DIR, 'derivatives', simname)\n",
    "        cell_grid = fct.load_grid(TEMP_DIR, 'positions',   simname)\n",
    "\n",
    "        cell_idx = fct.nu_in_which_cell(x_i, cell_grid)  # index of cell\n",
    "        grad_tot = dPsi_grid[cell_idx,:]                 # derivative of cell\n",
    "\n",
    "    # Neutrino outside cell grid.\n",
    "    else:\n",
    "        NrDM = NrDM_SNAPSHOTS[idx]\n",
    "        grad_tot = fct.outside_gravity(x_i, NrDM, PRE.DM_SIM_MASS)\n",
    "\n",
    "    # Switch to \"physical reality\" here.\n",
    "    grad_tot /= (kpc/s**2)\n",
    "    x_i /= kpc\n",
    "    u_i /= (kpc/s)\n",
    "\n",
    "    # Hamilton eqns. for integration.\n",
    "    dyds = -np.array([\n",
    "        u_i, 1./(1.+z)**2 * grad_tot\n",
    "    ])\n",
    "\n",
    "    return dyds\n",
    "\n",
    "\n",
    "def backtrack_1_neutrino(y0_Nr):\n",
    "    \"\"\"Simulate trajectory of 1 neutrino.\"\"\"\n",
    "\n",
    "    # Split input into initial vector and neutrino number.\n",
    "    y0, Nr = y0_Nr[0:-1], y0_Nr[-1]\n",
    "\n",
    "    # Solve all 6 EOMs.\n",
    "    sol = solve_ivp(\n",
    "        fun=EOMs, t_span=[S_STEPS[0], S_STEPS[-1]], t_eval=S_STEPS,\n",
    "        y0=y0, method=SOLVER, vectorized=True,\n",
    "        args=()\n",
    "        )\n",
    "    \n",
    "    np.save(f'{TEMP_DIR}/nu_{int(Nr)}.npy', np.array(sol.y.T))\n",
    "\n",
    "\n",
    "# =============================================== #\n",
    "# Run precalculations for selected halo in batch. #\n",
    "# =============================================== #\n",
    "\n",
    "manual_halo_index = 0  #! 0 to size-1, for submitting jobs manually\n",
    "halo_j, halo_ID = manual_halo_index, halo_batch_IDs[manual_halo_index]\n",
    "\n",
    "\n",
    "# Generate progenitor index array for current halo.\n",
    "splits = re.split('/', SIM_TYPE)\n",
    "MTname = f'{PRE.SIM}_{splits[0]}_{splits[1]}'\n",
    "proj_IDs = fct.read_MergerTree(PRE.OUT_DIR, MTname, halo_ID)\n",
    "\n",
    "# Create empty arrays to save specifics of each loop.\n",
    "save_GRID_L = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "save_num_DM = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "    \n",
    "j = 0\n",
    "snap = PRE.NUMS_SNAPS[::-1][0]\n",
    "proj_ID = proj_IDs[0]\n",
    "proj_ID = int(proj_ID)\n",
    "\n",
    "\n",
    "# --------------------------- #\n",
    "# Read and load DM positions. #\n",
    "# --------------------------- #\n",
    "\n",
    "IDname = f'origID{halo_ID}_snap_{snap}'\n",
    "fct.read_DM_halo_index(\n",
    "    snap, proj_ID, IDname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "DM_raw = np.load(f'{TEMP_DIR}/DM_pos_{IDname}.npy')\n",
    "DM_particles = len(DM_raw)\n",
    "\n",
    "\n",
    "# ---------------------- #\n",
    "# Cell division process. #\n",
    "# ---------------------- #\n",
    "\n",
    "# Initialize grid.\n",
    "snap_GRID_L = (int(np.abs(DM_raw).max()) + 1)*kpc\n",
    "raw_grid = fct.grid_3D(snap_GRID_L, snap_GRID_L)\n",
    "init_grid = np.expand_dims(raw_grid, axis=1)\n",
    "\n",
    "# Prepare arrays for cell division.\n",
    "DM_raw *= kpc\n",
    "DM_pos = np.expand_dims(DM_raw, axis=0)\n",
    "DM_pos_for_cell_division = np.repeat(DM_pos, len(init_grid), axis=0)\n",
    "del DM_raw\n",
    "\n",
    "# Cell division.\n",
    "cell_division_count = fct.cell_division(\n",
    "    init_grid, DM_pos_for_cell_division, snap_GRID_L, PRE.DM_LIM, None, TEMP_DIR, IDname\n",
    ")\n",
    "del DM_pos_for_cell_division\n",
    "\n",
    "# Load files from cell division.\n",
    "fin_grid = np.load(f'{TEMP_DIR}/fin_grid_{IDname}.npy')\n",
    "DM_count = np.load(f'{TEMP_DIR}/DM_count_{IDname}.npy')\n",
    "cell_com = np.load(f'{TEMP_DIR}/cell_com_{IDname}.npy')\n",
    "cell_gen = np.load(f'{TEMP_DIR}/cell_gen_{IDname}.npy')\n",
    "\n",
    "# Save snapshot specific parameters.\n",
    "save_GRID_L[j] = snap_GRID_L\n",
    "save_num_DM[j] = np.sum(DM_count)\n",
    "\n",
    "\n",
    "# --------------------------------------------- #\n",
    "# Calculate gravity grid (in batches of cells). #\n",
    "# --------------------------------------------- #\n",
    "cell_coords = np.squeeze(fin_grid, axis=1)\n",
    "cells = len(cell_coords)\n",
    "\n",
    "\n",
    "# -------------------- #\n",
    "# Short-range gravity. #\n",
    "# -------------------- #\n",
    "\n",
    "# Calculate available memory per core.\n",
    "mem_so_far = (psutil.virtual_memory().used - OS_MEM)/MB_UNIT\n",
    "mem_left = PRE.MEM_LIM_GB*1e3 - mem_so_far\n",
    "core_mem_MB = mem_left / PRE.PRE_CPUs\n",
    "\n",
    "# Determine short-range chuncksize based on available memory and cells.\n",
    "chunksize_sr = fct.chunksize_short_range(\n",
    "    cells, DM_particles, PRE.DM_LIM*SHELL_MULTIPLIERS[-1], core_mem_MB\n",
    ")\n",
    "\n",
    "# Split workload into batches (if necessary).\n",
    "batch_arr, cell_chunks, cgen_chunks = fct.batch_generators_short_range(\n",
    "    cell_coords, cell_gen, chunksize_sr\n",
    ")\n",
    "\n",
    "with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "    ex.map(\n",
    "        fct.cell_gravity_short_range, \n",
    "        cell_chunks, cgen_chunks, repeat(snap_GRID_L), \n",
    "        repeat(DM_pos), repeat(PRE.DM_LIM), repeat(PRE.DM_SIM_MASS), \n",
    "        repeat(PRE.SMOOTH_L), repeat(TEMP_DIR), batch_arr,\n",
    "        repeat(chunksize_sr)\n",
    "    )\n",
    "\n",
    "# Combine short-range batch files.\n",
    "dPsi_short_range_batches = [\n",
    "    np.load(f'{TEMP_DIR}/batch{b}_short_range.npy') for b in batch_arr\n",
    "]\n",
    "dPsi_short_range = np.array(\n",
    "    list(chain.from_iterable(dPsi_short_range_batches))\n",
    ")\n",
    "# np.save(\n",
    "#     f'{TEMP_DIR}/dPsi_short_range_{IDname}.npy', \n",
    "#     dPsi_short_range\n",
    "# )\n",
    "\n",
    "# Combine DM_in_cell_IDs batches (needed for long-range gravity).\n",
    "DM_in_cell_IDs_l = []\n",
    "for b_id in batch_arr:\n",
    "    DM_in_cell_IDs_l.append(\n",
    "        np.load(f'{TEMP_DIR}/batch{b_id}_DM_in_cell_IDs.npy')\n",
    "    )\n",
    "DM_in_cell_IDs_np = np.array(\n",
    "    list(chain.from_iterable(DM_in_cell_IDs_l)))\n",
    "np.save(f'{TEMP_DIR}/DM_in_cell_IDs_{IDname}.npy', DM_in_cell_IDs_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- #\n",
    "# Long-range gravity. #\n",
    "# ------------------- #\n",
    "\n",
    "# Calculate available memory per core.\n",
    "mem_so_far = (psutil.virtual_memory().used - OS_MEM)/MB_UNIT\n",
    "mem_left = PRE.MEM_LIM_GB*1e3 - mem_so_far\n",
    "core_mem_MB = mem_left / PRE.PRE_CPUs\n",
    "\n",
    "# Determine long-range chuncksize based on available memory and cells.\n",
    "# chunksize_lr = fct.chunksize_long_range(cells, core_mem_MB)\n",
    "chunksize_lr = 101\n",
    "\n",
    "# Split workload into batches (if necessary).\n",
    "DM_in_cell_IDs = np.load(f'{TEMP_DIR}/DM_in_cell_IDs_{IDname}.npy')\n",
    "batch_IDs, cellC_rep, cellC_cc, gen_rep, cib_IDs_gens, count_gens, com_gens, gen_gens = fct.batch_generators_long_range(\n",
    "    cell_coords, cell_com, cell_gen, DM_count, chunksize_lr\n",
    ")\n",
    "\n",
    "with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "    ex.map(\n",
    "        fct.cell_gravity_long_range_quadrupole, \n",
    "        cellC_rep, cib_IDs_gens, batch_IDs, \n",
    "        cellC_cc, com_gens, gen_gens, repeat(snap_GRID_L),\n",
    "        repeat(np.squeeze(DM_pos, axis=0)), count_gens, \n",
    "        repeat(DM_in_cell_IDs), repeat(PRE.DM_SIM_MASS), \n",
    "        repeat(TEMP_DIR), repeat(chunksize_lr), gen_rep\n",
    "    )\n",
    "\n",
    "\n",
    "# Combine long-range batch files.\n",
    "c_labels = np.unique(cellC_rep)\n",
    "b_labels = np.unique(batch_IDs)\n",
    "with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "    ex.map(\n",
    "        fct.load_dPsi_long_range, c_labels, \n",
    "        repeat(b_labels), repeat(TEMP_DIR)\n",
    "    )\n",
    "\n",
    "dPsi_long_range = np.array(\n",
    "    [np.load(f'{TEMP_DIR}/cell{c}_long_range.npy') for c in c_labels])\n",
    "\n",
    "# Combine short- and long-range forces.\n",
    "dPsi_grid = dPsi_short_range + dPsi_long_range\n",
    "np.save(f'{TEMP_DIR}/dPsi_grid_{IDname}.npy', dPsi_grid)\n",
    "\n",
    "\n",
    "# Save snapshot and halo specific arrays.\n",
    "np.save(f'{TEMP_DIR}/snaps_GRID_L_origID{halo_ID}.npy', save_GRID_L)\n",
    "np.save(f'{TEMP_DIR}/NrDM_snaps_origID{halo_ID}.npy', save_num_DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========================================= #\n",
    "# Run simulation for current halo in batch. #\n",
    "# ========================================= #\n",
    "\n",
    "# These arrays will be used in EOMs function above.\n",
    "snaps_GRID_L = np.load(\n",
    "    f'{TEMP_DIR}/snaps_GRID_L_origID{halo_ID}.npy')\n",
    "NrDM_SNAPSHOTS = np.load(\n",
    "    f'{TEMP_DIR}/NrDM_snaps_origID{halo_ID}.npy')\n",
    "\n",
    "\n",
    "print(f'***Running simulation with {PRE.SIM_CPUs} CPUs***')\n",
    "for i, (phi, theta) in enumerate(zip(hp_phis, hp_thetas)):\n",
    "\n",
    "    sim_start = time.perf_counter()\n",
    "\n",
    "    print(f'Coord. pair {i+1}/{len(hp_phis)}')\n",
    "\n",
    "    # Draw initial velocities.\n",
    "    ui = fct.init_velocities(phi, theta, PRE.MOMENTA, all_sky=True)\n",
    "\n",
    "    # Combine vectors and append neutrino particle number.\n",
    "    y0_Nr = np.array(\n",
    "        [np.concatenate((X_SUN, ui[k], [k+1])) for k in range(PRE.Vs)]\n",
    "        )\n",
    "    \n",
    "    sim_testing = False\n",
    "\n",
    "    if sim_testing:\n",
    "        # Test 1 neutrino only.\n",
    "        backtrack_1_neutrino(y0_Nr[0])\n",
    "\n",
    "    else:\n",
    "        # Run simulation on multiple cores.\n",
    "        with ProcessPoolExecutor(PRE.SIM_CPUs) as ex:\n",
    "            ex.map(backtrack_1_neutrino, y0_Nr)\n",
    "\n",
    "\n",
    "        # Compactify all neutrino vectors into 1 file.\n",
    "        Ns = np.arange(PRE.Vs, dtype=int)            \n",
    "        nus = [np.load(f'{TEMP_DIR}/nu_{Nr+1}.npy') for Nr in Ns]\n",
    "        CPname = f'{PRE.NUS}nus_{hname}_halo{halo_j}_CoordPair{i+1}'\n",
    "        np.save(f'{TEMP_DIR}/{CPname}.npy', np.array(nus))\n",
    "\n",
    "        # Calculate local overdensity.\n",
    "        vels = fct.load_sim_data(TEMP_DIR, CPname, 'velocities')\n",
    "\n",
    "        # note: The final number density is not stored in the temporary folder.\n",
    "        out_file = f'{PRE.OUT_DIR}/number_densities_all_sky_{CPname}.npy'\n",
    "        fct.number_densities_mass_range(\n",
    "            vels, NU_MRANGE, out_file, pix_sr\n",
    "        )\n",
    "\n",
    "        # Now delete velocities and distances of this coord. pair. neutrinos.\n",
    "        fct.delete_temp_data(f'{TEMP_DIR}/{CPname}.npy')\n",
    "\n",
    "        seconds = time.perf_counter()-sim_start\n",
    "        minutes = seconds/60.\n",
    "        hours = minutes/60.\n",
    "        print(f'Sim time min/h: {minutes} min, {hours} h.')\n",
    "\n",
    "# Remove temporary folder with all individual neutrino files.\n",
    "# shutil.rmtree(TEMP_DIR)\n",
    "\n",
    "total_time = time.perf_counter()-total_start\n",
    "print(f'Total time: {total_time/60.} min, {total_time/(60**2)} h.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
