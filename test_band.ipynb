{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save how much memory is used by OS and not available for script.\n",
    "import psutil\n",
    "MB_UNIT = 1024**2\n",
    "OS_MEM = (psutil.virtual_memory().used)\n",
    "\n",
    "\n",
    "from shared.preface import *\n",
    "import shared.functions as fct\n",
    "\n",
    "# --------------------------------- #\n",
    "# Find starting IDs for halo batch. #\n",
    "# --------------------------------- #\n",
    "\n",
    "total_start = time.perf_counter()\n",
    "\n",
    "# Initialize parameters and files.\n",
    "PRE = PRE(\n",
    "    sim='L025N752', \n",
    "    z0_snap=36, z4_snap=13, DM_lim=10000,\n",
    "    sim_dir=SIM_ROOT, sim_ver=SIM_TYPE,\n",
    "    phis=10, thetas=10, vels=100,\n",
    "    pre_CPUs=128, sim_CPUs=128, mem_lim_GB=224\n",
    ")\n",
    "\n",
    "# Make temporary folder to store files, s.t. parallel runs don't clash.\n",
    "rand_code = ''.join(\n",
    "    random.choices(string.ascii_uppercase + string.digits, k=4)\n",
    ")\n",
    "TEMP_DIR = f'{PRE.OUT_DIR}/temp_data_{rand_code}'\n",
    "os.makedirs(TEMP_DIR)\n",
    "\n",
    "Testing=False\n",
    "if Testing:\n",
    "    mass_gauge = 12.3\n",
    "    mass_range = 0.3\n",
    "    size = 1\n",
    "else:\n",
    "    mass_gauge = 12.0\n",
    "    mass_range = 0.6\n",
    "    size = 3\n",
    "\n",
    "hname = f'1e+{mass_gauge}_pm{mass_range}Msun'\n",
    "fct.halo_batch_indices(\n",
    "    PRE.Z0_STR, mass_gauge, mass_range, 'halos', size, \n",
    "    hname, PRE.SIM_DIR, TEMP_DIR\n",
    ")\n",
    "halo_batch_IDs = np.load(f'{TEMP_DIR}/halo_batch_{hname}_indices.npy')\n",
    "halo_batch_params = np.load(f'{TEMP_DIR}/halo_batch_{hname}_params.npy')\n",
    "halo_num = len(halo_batch_params)\n",
    "\n",
    "print('********Number density band********')\n",
    "print('Halo batch params (Rvir,Mvir,cNFW):')\n",
    "print(halo_batch_params)\n",
    "print('***********************************')\n",
    "\n",
    "\n",
    "def EOMs(s_val, y):\n",
    "\n",
    "    # Initialize vector.\n",
    "    x_i, u_i = np.reshape(y, (2,3))\n",
    "\n",
    "    # Switch to \"numerical reality\" here.\n",
    "    x_i *= kpc\n",
    "    u_i *= (kpc/s)\n",
    "\n",
    "    # Find z corresponding to s via interpolation.\n",
    "    z = np.interp(s_val, S_STEPS, ZEDS)\n",
    "\n",
    "    # Snapshot specific parameters.\n",
    "    idx = np.abs(PRE.ZEDS_SNAPS - z).argmin()\n",
    "    snap = PRE.NUMS_SNAPS[idx]\n",
    "    snap_GRID_L = snaps_GRID_L[idx]\n",
    "\n",
    "    # Neutrino inside cell grid.\n",
    "    if np.all(np.abs(x_i)) <= snap_GRID_L:\n",
    "\n",
    "        # Find which (pre-calculated) derivative grid to use at current z.\n",
    "        simname = f'origID{halo_ID}_snap_{snap}'\n",
    "        dPsi_grid = fct.load_grid(TEMP_DIR, 'derivatives', simname)\n",
    "        cell_grid = fct.load_grid(TEMP_DIR, 'positions',   simname)\n",
    "\n",
    "        cell_idx = fct.nu_in_which_cell(x_i, cell_grid)  # index of cell\n",
    "        grad_tot = dPsi_grid[cell_idx,:]                 # derivative of cell\n",
    "\n",
    "    # Neutrino outside cell grid.\n",
    "    else:\n",
    "        NrDM = NrDM_SNAPSHOTS[idx]\n",
    "        grad_tot = fct.outside_gravity(x_i, NrDM, PRE.DM_SIM_MASS)\n",
    "\n",
    "    # Switch to \"physical reality\" here.\n",
    "    grad_tot /= (kpc/s**2)\n",
    "    x_i /= kpc\n",
    "    u_i /= (kpc/s)\n",
    "\n",
    "    # Hamilton eqns. for integration.\n",
    "    dyds = -np.array([\n",
    "        u_i, 1./(1.+z)**2 * grad_tot\n",
    "    ])\n",
    "\n",
    "    return dyds\n",
    "\n",
    "\n",
    "def backtrack_1_neutrino(y0_Nr):\n",
    "    \"\"\"Simulate trajectory of 1 neutrino.\"\"\"\n",
    "\n",
    "    # Split input into initial vector and neutrino number.\n",
    "    y0, Nr = y0_Nr[0:-1], y0_Nr[-1]\n",
    "\n",
    "    # Solve all 6 EOMs.\n",
    "    sol = solve_ivp(\n",
    "        fun=EOMs, t_span=[S_STEPS[0], S_STEPS[-1]], t_eval=S_STEPS,\n",
    "        y0=y0, method=SOLVER, vectorized=True,\n",
    "        args=()\n",
    "        )\n",
    "    \n",
    "    np.save(f'{TEMP_DIR}/nu_{int(Nr)}.npy', np.array(sol.y.T))\n",
    "\n",
    "\n",
    "for halo_j, halo_ID in enumerate(halo_batch_IDs):\n",
    "\n",
    "    # ============================================== #\n",
    "    # Run precalculations for current halo in batch. #\n",
    "    # ============================================== #\n",
    "\n",
    "    # Generate progenitor index array for current halo.\n",
    "    splits = re.split('/', SIM_TYPE)\n",
    "    MTname = f'{PRE.SIM}_{splits[0]}_{splits[1]}'\n",
    "    proj_IDs = fct.read_MergerTree(PRE.OUT_DIR, MTname, halo_ID)\n",
    "\n",
    "    save_GRID_L = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "    save_num_DM = np.zeros(len(PRE.NUMS_SNAPS))\n",
    "    for j, (snap, proj_ID) in enumerate(zip(\n",
    "        PRE.NUMS_SNAPS[::-1], proj_IDs\n",
    "    )):\n",
    "        print(f'halo {halo_j+1}/{halo_num} ; snapshot {snap}')\n",
    "        \n",
    "        proj_ID = int(proj_ID)\n",
    "\n",
    "\n",
    "        # --------------------------- #\n",
    "        # Read and load DM positions. #\n",
    "        # --------------------------- #\n",
    "\n",
    "        IDname = f'origID{halo_ID}_snap_{snap}'\n",
    "        fct.read_DM_halo_index(\n",
    "            snap, proj_ID, IDname, PRE.SIM_DIR, TEMP_DIR\n",
    "        )\n",
    "        DM_raw = np.load(f'{TEMP_DIR}/DM_pos_{IDname}.npy')\n",
    "        DM_particles = len(DM_raw)\n",
    "\n",
    "        # ---------------------- #\n",
    "        # Cell division process. #\n",
    "        # ---------------------- #\n",
    "\n",
    "        # Initialize grid.\n",
    "        snap_GRID_L = (int(np.abs(DM_raw).max()) + 1)*kpc\n",
    "        raw_grid = fct.grid_3D(snap_GRID_L, snap_GRID_L)\n",
    "        init_grid = np.expand_dims(raw_grid, axis=1)\n",
    "\n",
    "        # Prepare arrays for cell division.\n",
    "        DM_raw *= kpc\n",
    "        DM_pos = np.expand_dims(DM_raw, axis=0)\n",
    "        DM_pos_for_cell_division = np.repeat(DM_pos, len(init_grid), axis=0)\n",
    "        del DM_raw\n",
    "\n",
    "        # Cell division.\n",
    "        cell_division_count = fct.cell_division(\n",
    "            init_grid, DM_pos_for_cell_division, snap_GRID_L, PRE.DM_LIM, None, TEMP_DIR, IDname\n",
    "        )\n",
    "        del DM_pos_for_cell_division\n",
    "\n",
    "        # Load files from cell division.\n",
    "        fin_grid = np.load(f'{TEMP_DIR}/fin_grid_{IDname}.npy')\n",
    "        DM_count = np.load(f'{TEMP_DIR}/DM_count_{IDname}.npy')\n",
    "        cell_com = np.load(f'{TEMP_DIR}/cell_com_{IDname}.npy')\n",
    "        cell_gen = np.load(f'{TEMP_DIR}/cell_gen_{IDname}.npy')\n",
    "        \n",
    "        # Save snapshot specific parameters.\n",
    "        save_GRID_L[j] = snap_GRID_L\n",
    "        save_num_DM[j] = np.sum(DM_count)\n",
    "\n",
    "\n",
    "        # --------------------------------------------- #\n",
    "        # Calculate gravity grid (in batches of cells). #\n",
    "        # --------------------------------------------- #\n",
    "        cell_coords = np.squeeze(fin_grid, axis=1)\n",
    "        cells = len(cell_coords)\n",
    "\n",
    "        ### Short-range gravity.\n",
    "\n",
    "        # Calculate available memory per core.\n",
    "        mem_so_far = (psutil.virtual_memory().used - OS_MEM)/MB_UNIT\n",
    "        mem_left = PRE.MEM_LIM_GB*1e3 - mem_so_far\n",
    "        core_mem_MB = mem_left / PRE.PRE_CPUs\n",
    "\n",
    "        # Determine short-range chuncksize based on available memory and cells.\n",
    "        chunksize_sr = fct.chunksize_short_range(\n",
    "            cells, DM_particles, PRE.DM_LIM*SHELL_MULTIPLIERS[-1], core_mem_MB\n",
    "        )\n",
    "\n",
    "        # Split workload into batches (if necessary).\n",
    "        batch_arr, cell_chunks, cgen_chunks = fct.batch_generators_short_range(\n",
    "            cell_coords, cell_gen, chunksize_sr\n",
    "        )\n",
    "\n",
    "        with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "            ex.map(\n",
    "                fct.cell_gravity_short_range, \n",
    "                cell_chunks, cgen_chunks, repeat(snap_GRID_L), repeat(DM_pos), \n",
    "                repeat(PRE.DM_LIM), repeat(PRE.DM_SIM_MASS), \n",
    "                repeat(PRE.SMOOTH_L), repeat(TEMP_DIR), batch_arr\n",
    "            )\n",
    "\n",
    "        # Combine short-range batch files.\n",
    "        dPsi_short_range_batches = [\n",
    "            np.load(f'{TEMP_DIR}/batch{b}_short_range.npy') for b in batch_arr\n",
    "        ]\n",
    "        dPsi_short_range = np.array(\n",
    "            list(chain.from_iterable(dPsi_short_range_batches))\n",
    "        )\n",
    "        np.save(\n",
    "            f'{TEMP_DIR}/dPsi_short_range_{IDname}.npy', \n",
    "            dPsi_short_range\n",
    "        )\n",
    "\n",
    "\n",
    "        ### Long-range gravity.\n",
    "\n",
    "        # Calculate available memory per core.\n",
    "        mem_so_far = (psutil.virtual_memory().used - OS_MEM)/MB_UNIT\n",
    "        mem_left = PRE.MEM_LIM_GB*1e3 - mem_so_far\n",
    "        core_mem_MB = mem_left / PRE.PRE_CPUs\n",
    "\n",
    "        # Determine long-range chuncksize based on available memory and cells.\n",
    "        chunksize_lr = fct.chunksize_long_range(cells, core_mem_MB)\n",
    "\n",
    "        # Split workload into batches (if necessary).\n",
    "        cell_ids, batches, coords, count_chain, com_chain = fct.batch_generators_long_range(\n",
    "            cell_coords, cell_com, DM_count, chunksize_lr\n",
    "        )\n",
    "\n",
    "        with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "            ex.map(\n",
    "                fct.cell_gravity_long_range, cell_ids, batches, \n",
    "                coords, count_chain, com_chain,\n",
    "                repeat(PRE.DM_SIM_MASS), repeat(PRE.SMOOTH_L), repeat(TEMP_DIR)\n",
    "            )\n",
    "\n",
    "\n",
    "        # Combine long-range batch files.\n",
    "        with ProcessPoolExecutor(PRE.PRE_CPUs) as ex:\n",
    "            ex.map(\n",
    "                fct.load_dPsi_long_range, cell_ids, \n",
    "                repeat(batches), repeat(TEMP_DIR)\n",
    "            )\n",
    "\n",
    "        dPsi_long_range = [\n",
    "            np.load(f'{TEMP_DIR}/cell{c}_long_range.npy') for c in cell_ids\n",
    "        ]\n",
    "        np.save(\n",
    "            f'{TEMP_DIR}/dPsi_long_range_{IDname}.npy', \n",
    "            np.array(dPsi_long_range)\n",
    "        )\n",
    "\n",
    "\n",
    "        # Combine short- and long-range forces.\n",
    "        gravity_sr = np.load(f'{TEMP_DIR}/dPsi_short_range_{IDname}.npy')\n",
    "        gravity_lr = np.load(f'{TEMP_DIR}/dPsi_long_range_{IDname}.npy')\n",
    "        dPsi_grid = gravity_sr + gravity_lr\n",
    "        np.save(f'{TEMP_DIR}/dPsi_grid_{IDname}.npy', dPsi_grid)\n",
    "\n",
    "\n",
    "    # Save snapshot and halo specific arrays.\n",
    "    np.save(f'{TEMP_DIR}/snaps_GRID_L_origID{halo_ID}.npy', save_GRID_L)\n",
    "    np.save(f'{TEMP_DIR}/NrDM_snaps_origID{halo_ID}.npy', save_num_DM)\n",
    "\n",
    "\n",
    "    # ========================================= #\n",
    "    # Run simulation for current halo in batch. #\n",
    "    # ========================================= #\n",
    "\n",
    "    # These arrays will be used in EOMs function above.\n",
    "    snaps_GRID_L = np.load(\n",
    "        f'{TEMP_DIR}/snaps_GRID_L_origID{halo_ID}.npy')\n",
    "    NrDM_SNAPSHOTS = np.load(\n",
    "        f'{TEMP_DIR}/NrDM_snaps_origID{halo_ID}.npy')\n",
    "\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # Draw initial velocities.\n",
    "    ui = fct.init_velocities(PRE.PHIs, PRE.THETAs, PRE.MOMENTA)\n",
    "\n",
    "    # Combine vectors and append neutrino particle number.\n",
    "    y0_Nr = np.array(\n",
    "        [np.concatenate((X_SUN, ui[i], [i+1])) for i in range(PRE.NUS)]\n",
    "        )\n",
    "\n",
    "\n",
    "    # Display parameters for simulation.\n",
    "    print('***Running simulation***')\n",
    "    print(f'halo={halo_j+1}/{halo_num}, CPUs={PRE.SIM_CPUs}')\n",
    "\n",
    "    sim_testing = False\n",
    "\n",
    "    if sim_testing:\n",
    "        # Test 1 neutrino only.\n",
    "        backtrack_1_neutrino(y0_Nr[0])\n",
    "\n",
    "    else:\n",
    "        # Run simulation on multiple cores.\n",
    "        with ProcessPoolExecutor(PRE.SIM_CPUs) as ex:\n",
    "            ex.map(backtrack_1_neutrino, y0_Nr)\n",
    "\n",
    "\n",
    "        # Compactify all neutrino vectors into 1 file.\n",
    "        Ns = np.arange(PRE.NUS, dtype=int)            \n",
    "        nus = [np.load(f'{TEMP_DIR}/nu_{Nr+1}.npy') for Nr in Ns]\n",
    "        Bname = f'{PRE.NUS}nus_{hname}_halo{halo_j}_band'\n",
    "        np.save(f'{TEMP_DIR}/{Bname}.npy', np.array(nus))\n",
    "\n",
    "        # Calculate local overdensity.\n",
    "        nu_mass_range = np.geomspace(0.01, 0.3, 100)*eV\n",
    "        vels_CoordPair = fct.load_sim_data(TEMP_DIR, Bname, 'velocities')\n",
    "\n",
    "        # note: The final number density is not stored in the temporary folder.\n",
    "        #? how to name this file?\n",
    "        out_file = f'{PRE.OUT_DIR}/number_densities_{Bname}_???.npy'\n",
    "        fct.number_densities_mass_range(\n",
    "            vels_CoordPair, nu_mass_range, out_file\n",
    "        )\n",
    "\n",
    "        # Now delete velocities and distances of this coord. pair. neutrinos.\n",
    "        fct.delete_temp_data(f'{TEMP_DIR}/{Bname}.npy')\n",
    "\n",
    "\n",
    "        seconds = time.perf_counter()-start\n",
    "        minutes = seconds/60.\n",
    "        hours = minutes/60.\n",
    "        print(f'Sim time min/h: {minutes} min, {hours} h.')\n",
    "\n",
    "# Remove temporary folder with all individual neutrino files.\n",
    "shutil.rmtree(TEMP_DIR)\n",
    "\n",
    "total_time = time.perf_counter()-total_start\n",
    "print(f'Total time: {total_time/60.} min, {total_time/(60**2)} h.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
