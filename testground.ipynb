{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.preface import *\n",
    "import shared.functions as fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0012', '0013', '0014', '0015', '0016', '0017', '0018', '0019',\n",
       "       '0020', '0021', '0022', '0023', '0024', '0025', '0026', '0027',\n",
       "       '0028', '0029', '0030', '0031', '0032', '0033', '0034', '0035',\n",
       "       '0036'], dtype='<U4')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMS_SNAPSHOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2465, 1, 3) 2613675\n",
      "(2346, 1, 3) 2470675\n",
      "(2136, 1, 3) 2327887\n",
      "(2108, 1, 3) 2231543\n",
      "(1968, 1, 3) 2171392\n",
      "(1835, 1, 3) 2109376\n",
      "(1835, 1, 3) 2078631\n",
      "(1807, 1, 3) 2034215\n",
      "(1632, 1, 3) 2050828\n",
      "(1527, 1, 3) 1982651\n",
      "(1534, 1, 3) 1939286\n",
      "(1576, 1, 3) 1928477\n",
      "(1527, 1, 3) 1924680\n",
      "(1485, 1, 3) 1926552\n",
      "(1450, 1, 3) 1935274\n",
      "(1457, 1, 3) 1943945\n",
      "(1499, 1, 3) 1968765\n",
      "(1597, 1, 3) 2020452\n",
      "(1485, 1, 3) 2035865\n",
      "(1555, 1, 3) 2063480\n",
      "(1611, 1, 3) 2078369\n",
      "(1681, 1, 3) 2089249\n"
     ]
    }
   ],
   "source": [
    "for s in NUMS_SNAPSHOTS[3:]:\n",
    "    g = np.load(\n",
    "        f'CubeSpace/adapted_cc_L006N188_snapshot_{s}_1.89e+12Msun_800.0kpc.npy'\n",
    "    )\n",
    "    c = np.load(\n",
    "        f'CubeSpace/DM_count_L006N188_snapshot_{s}_1.89e+12Msun_800.0kpc.npy'\n",
    "    )\n",
    "    \n",
    "    print(g.shape, c.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snippets for cell division function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_GRID_S = GRID_S\n",
    "sub8_GRID_S = parent_GRID_S/2.\n",
    "sub8_raw = fct.grid_3D(sub8_GRID_S, sub8_GRID_S)\n",
    "# print(sub8_raw/kpc)\n",
    "\n",
    "pcs = 5  # amount of parent cells\n",
    "sub8_temp = np.tile(sub8_raw, (pcs,1)).reshape((pcs, 8, 3))\n",
    "# print(sub8_temp/kpc, sub8_temp.shape)\n",
    "\n",
    "parent_cc = np.zeros((pcs,1,3))\n",
    "parent_cc[1,...] += 2\n",
    "parent_cc[4,...] += 2\n",
    "parent_cc *= kpc\n",
    "print(parent_cc/kpc)\n",
    "\n",
    "sub8_coords = np.reshape(sub8_temp + parent_cc, (pcs*8, 1, 3))\n",
    "print(sub8_coords/kpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_count = np.zeros(len(parent_cc))\n",
    "DM_count[[1,3]] += 1\n",
    "trimmed_cc = np.delete(parent_cc, np.s_[DM_count==0], axis=0)\n",
    "print(trimmed_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_DM = np.random.random((2,4,3))\n",
    "rand_DM[:,3:,:] = np.nan\n",
    "# print(rand_DM)\n",
    "\n",
    "DM_re = rand_DM.reshape((2*4,3))\n",
    "DM_sort = np.sort(DM_re, axis=0)\n",
    "# print(DM_sort)\n",
    "\n",
    "max_row = np.count_nonzero(~np.isnan(DM_sort[:,0]))\n",
    "# print(max_row)\n",
    "\n",
    "DM_trunc = np.delete(DM_sort, np.s_[max_row:], axis=0)\n",
    "\n",
    "# print(DM_trunc)\n",
    "\n",
    "DM_unique = np.unique(DM_trunc, axis=1)\n",
    "# print(DM_unique)\n",
    "\n",
    "len1 = len(DM_unique)\n",
    "len2 = len(DM_trunc)\n",
    "print(len1==len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_nonan = DM_reset[~np.isnan(DM_reset)]\n",
    "print(DM_nonan.shape)\n",
    "\n",
    "len1 = len(np.unique(DM_nonan.flatten()))\n",
    "len2 = len(DM_nonan.flatten())\n",
    "print(len1==len2, len1, len2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_pos = np.random.randint(-10, 10, (2,5,3))\n",
    "DM_pos = np.asarray(DM_pos, dtype=np.float64)\n",
    "DM_pos[:,1:3,:] = np.nan\n",
    "print(DM_pos)\n",
    "\n",
    "ind_2D = DM_pos[:,:,0].argsort(axis=1)\n",
    "ind_3D = np.repeat(np.expand_dims(ind_2D, axis=2), 3, axis=2)\n",
    "\n",
    "DM_pos_sort = np.take_along_axis(DM_pos, ind_3D, axis=1)\n",
    "print(DM_pos_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = np.random.randint(-10, 10, (2,5,3))\n",
    "\n",
    "print(parts)\n",
    "\n",
    "cell_len = np.ones((len(parts),1))*7\n",
    "print(cell_len.shape)\n",
    "cell_len[0] = 5\n",
    "\n",
    "parts_in = np.asarray(\n",
    "    (np.abs(parts[:,:,0]) <= cell_len) &\n",
    "    (np.abs(parts[:,:,1]) <= cell_len) &\n",
    "    (np.abs(parts[:,:,2]) <= cell_len)\n",
    ")\n",
    "\n",
    "print(parts_in)\n",
    "\n",
    "parts = np.asarray(parts, dtype=np.float64)\n",
    "\n",
    "parts[~parts_in] = np.nan\n",
    "\n",
    "print(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output of cell disvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_cc = np.load('CubeSpace/adapted_cc_L006N188_snapshot_0036.npy')\n",
    "DM_raw = np.load(\n",
    "    'CubeSpace/DM_positions_L006N188_snapshot_0036_2.59e+11Msun.npy')\n",
    "DM_count = np.load('CubeSpace/DM_count_L006N188_snapshot_0036.npy')\n",
    "cell_com = np.load('CubeSpace/cell_com_L006N188_snapshot_0036.npy')\n",
    "cell_gen = np.load('CubeSpace/cell_gen_L006N188_snapshot_0036.npy')\n",
    "\n",
    "print(adapted_cc.shape, DM_raw.shape, DM_count.shape, cell_com.shape, cell_gen.shape)\n",
    "print(np.sum(DM_count))\n",
    "print(type(cell_com.shape[0]))\n",
    "\n",
    "cell_com_rep = np.repeat(\n",
    "        np.expand_dims(cell_com, axis=1), adapted_cc.shape[0], axis=1\n",
    "    )\n",
    "print(cell_com_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting only certain element for each column of 3D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((3,3), int)\n",
    "np.fill_diagonal(a, 1)\n",
    "print(a)\n",
    "\n",
    "t0 = np.arange(9).reshape(3,3)\n",
    "print(t0[~a.astype(dtype=bool)].reshape(3,2))\n",
    "\n",
    "a = np.repeat(np.expand_dims(a, axis=2), 3, axis=2)\n",
    "# print(a)\n",
    "\n",
    "t1 = np.arange(27).reshape(3,3,3)\n",
    "# print(t1)\n",
    "print(t1[~a.astype(dtype=bool)].reshape(3,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that use/make files:\n",
    "- read_DM_positions\n",
    "- cell_division\n",
    "- cell_gravity_3D\n",
    "- load_grid\n",
    "- load_u_sim\n",
    "- load_x_sim\n",
    "\n",
    "Scripts that use/make files:\n",
    "- discrete_precalculations_MW.py\n",
    "- discrete_simulation_MW.py\n",
    "- merger_tree.py\n",
    "- smooth_simulation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuParser(object):\n",
    "\n",
    "    input_x: str\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        parser = argparse.ArgumentParser(\n",
    "            description=\"Argument Parser for Neutrino Clustering pipeline.\"\n",
    "        )\n",
    "\n",
    "        parser.add_argument(\n",
    "            \"-x\",\n",
    "            \"--long_name_x\",\n",
    "            help=\"explain what x does\",\n",
    "            type=str,\n",
    "            required=True\n",
    "        )\n",
    "\n",
    "        args = parser.parse_args()\n",
    "\n",
    "        self.input_x = args.long_name_x\n",
    "\n",
    "\n",
    "        print(\"{Parsed arguments:\")\n",
    "        print(\"---------------------\\n\")\n",
    "        print(f\"Parameter x: {self.input_x}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearranging 2D array along one axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2D = np.arange(6).reshape(2,3)\n",
    "print(x2D)\n",
    "\n",
    "ind2D = np.array([[1,0,2], [2,1,0]])\n",
    "\n",
    "ax0 = np.arange(x2D.shape[0])[:,None]\n",
    "\n",
    "print(ax0.shape, ind2D.shape)\n",
    "\n",
    "new_x2D = x2D[ax0, ind2D]\n",
    "print(new_x2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearranging 3D array along one axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3D = np.arange(18).reshape(2,3,3)\n",
    "print(x3D)\n",
    "ind3D = np.array([[1,0,2], [2,1,0]])[:,:,None]\n",
    "\n",
    "ax0 = np.arange(x3D.shape[0])[:,None,None]\n",
    "ax2 = np.arange(x3D.shape[2])[None,None,:]\n",
    "\n",
    "new_x3D = x3D[ax0,ind3D,ax2]\n",
    "print(new_x3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversions between momentum to velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NU_MASSES = np.array([0.01, 0.05, 0.1, 0.3])*eV\n",
    "Vs = 100\n",
    "LOWER = 0.01*T_CNB\n",
    "UPPER = 400*T_CNB\n",
    "\n",
    "# Momentum range.\n",
    "MOMENTA = np.geomspace(LOWER, UPPER, Vs)\n",
    "\n",
    "\n",
    "# Without Lorentz factor.\n",
    "v_mins = np.zeros(len(NU_MASSES))\n",
    "v_maxs = np.zeros(len(NU_MASSES))\n",
    "for i, m_nu in enumerate(NU_MASSES):\n",
    "    v_km = MOMENTA / m_nu / (m/s)\n",
    "    v_min, v_max = v_km[0], v_km[-1]\n",
    "    print(f'(m/s) -> v_min = {v_min:.2f}, v_max = {v_max:.2f}, %c = {v_max/const.c.value*100:.2f} : for {m_nu} eV neutrino')\n",
    "\n",
    "    v_mins[i] = v_min\n",
    "    v_maxs[i] = v_max\n",
    "\n",
    "\n",
    "# for m_nu in NU_MASSES:\n",
    "\n",
    "\n",
    "\n",
    "# With Lorentz factor.\n",
    "v_mins = np.zeros(len(NU_MASSES))\n",
    "v_maxs = np.zeros(len(NU_MASSES))\n",
    "for m_nu in NU_MASSES:\n",
    "    v_km = 1/np.sqrt(m_nu**2/MOMENTA**2 + 1) / (m/s)\n",
    "    v_min, v_max = v_km[0], v_km[-1]\n",
    "    print(f'(m/s) -> v_min = {v_min:.2f}, v_max = {v_max:.2f}, %c = {v_max/const.c.value*100:.2f} : for {m_nu} eV neutrino')\n",
    "\n",
    "\n",
    "#! Since the sim is using 0.3 eV mass, the max. velocity present in the sim is \n",
    "#! ~20% of c, not the ~98% of the 0.01 eV neutrino (see output of cell).\n",
    "\n",
    "\n",
    "# Back to momentum to check formulas & functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates of Andromeda (AG) and the Virgo Cluster (VC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-check with values in Mertsch et al. (2020).\n",
    "# -> x and y coords. are switched, since our setup is different,\n",
    "# and my x (their y) coords. differ by 8.5 kpc due to placement of sun\n",
    "# on our x-axis.\n",
    "coords_VC = fct.halo_pos(GLAT_VC, GLON_VC, DIST_VC/kpc)\n",
    "print(coords_VC, 'in kpc')\n",
    "coords_AG = fct.halo_pos(GLAT_AG, GLON_AG, DIST_AG/kpc)\n",
    "print(coords_AG, 'in kpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values in Table 1 of Mertsch et al. (2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rvir_Tab1 = fct.R_vir_fct(0, Mvir_MW)\n",
    "print(Rvir_Tab1/kpc)\n",
    "c_vir_Tab1 = fct.c_vir(0, Mvir_MW, Rvir_MW, Rs_MW)\n",
    "Rs_Tab1 = Rvir_Tab1 / c_vir_Tab1\n",
    "print(Rs_Tab1/kpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical density of universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_crit_today = fct.rho_crit(0)\n",
    "print(f'{rho_crit_today*(Msun/kpc**3)/(kg/m**3):.2e} kg/m^3') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Variable s(z) and comparison to age of universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In s_of_z function we use\n",
    "H0_mod = H0/ (1/s)\n",
    "print(H0_mod)\n",
    "\n",
    "test_z = 1\n",
    "s_val = fct.s_of_z(test_z)\n",
    "print(f'Value of time variable s in seconds at redhshift {test_z}:','\\n', s_val)\n",
    "print(\n",
    "    'Age of universe comparison: \\n', \n",
    "    f'\"Observed/measured\": {t0/s:.2e}, i.e. {t0/Gyr:.2f} Gyr \\n', \n",
    "    f'What we use in s_of_z function: {1/H0/s:.2e}, i.e. {1/H0/Gyr:.2f} Gyr'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrals for cosmic time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_integrand_a(a):\n",
    "\n",
    "    # We need value of H0 in units of 1/s.\n",
    "    H0_val = H0/(1/s)\n",
    "\n",
    "    a_dot = np.sqrt(Omega_M/a**3 + Omega_L)*H0_val*a\n",
    "    t_int = 1./a_dot\n",
    "\n",
    "    return t_int\n",
    "\n",
    "t, err = quad(t_integrand_a, 0, 1)\n",
    "t_uni, err_uni = t, err\n",
    "print(t_uni*s/Gyr, err_uni*s/Gyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_integrand_z(z):\n",
    "\n",
    "    # We need value of H0 in units of 1/s.\n",
    "    H0_val = H0/(1/s)\n",
    "\n",
    "    a_dot = np.sqrt(Omega_M*(1.+z)**3 + Omega_L)*H0_val*(1.+z)\n",
    "    t_int = 1./a_dot\n",
    "\n",
    "    return t_int\n",
    "\n",
    "t, err = quad(t_integrand_z, 0, np.inf)\n",
    "t_uni, err_uni = t, err\n",
    "print(t_uni*s/Gyr, err_uni*s/Gyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fermi-Dirac distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_test_range = np.linspace(0.01, 10)*T_CNB\n",
    "FD_range = fct.Fermi_Dirac(p_test_range)\n",
    "\n",
    "plt.loglog(p_test_range/T_CNB, FD_range)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift array for integration steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear spacing.\n",
    "# late_steps = 200\n",
    "# early_steps = 100\n",
    "# Z_START, Z_STOP, Z_AMOUNT = 0., 4., late_steps+early_steps\n",
    "# z_late = np.linspace(0,1,late_steps)\n",
    "# z_early = np.linspace(1.01,4,early_steps)\n",
    "# ZEDS = np.concatenate((z_late, z_early))\n",
    "\n",
    "# Logarithmic spacing.\n",
    "Z_START, Z_STOP, Z_AMOUNT = 0., 4., 300-1  # -1 to compensate np.insert of z=4\n",
    "Z_START_LOG = 1e-1\n",
    "zeds_pre = np.geomspace(Z_START_LOG, Z_STOP, Z_AMOUNT) - Z_START_LOG\n",
    "ZEDS = np.insert(zeds_pre, len(zeds_pre), 4.)\n",
    "\n",
    "plt.scatter(ZEDS, ZEDS, s=1)\n",
    "plt.show()\n",
    "print(ZEDS[0:10], ZEDS[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redshift z of each snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = 'L006N188'\n",
    "\n",
    "zeds = np.zeros(25)\n",
    "nums = []\n",
    "for j, i in enumerate(range(12,37)):\n",
    "    snap_i = f'{i:04d}'\n",
    "    nums.append(snap_i)\n",
    "\n",
    "    with h5py.File(str(next(\n",
    "        pathlib.Path(\n",
    "            f'{SIM_DATA}/{sim}').glob(f'**/snapshot_{snap_i}.hdf5'\n",
    "        )\n",
    "    ))) as snap:\n",
    "        zeds[j] = snap['Cosmology'].attrs['Redshift'][0]\n",
    "\n",
    "np.save(f'shared/ZEDS_SNAPSHOTS.npy', np.asarray(zeds))\n",
    "np.save(f'shared/NUMS_SNAPSHOTS.npy', np.asarray(nums))\n",
    "print(np.round(np.asarray(zeds),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFW density profile fct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_range = np.geomspace(1e-3, 100, 100)*kpc\n",
    "NFW_vals = fct.NFW_profile(r_range, rho0_MW, Rs_MW)\n",
    "plt.loglog(r_range/kpc, NFW_vals/(GeV/cm**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typical grav. potential gradient vectors in spher. symmetric simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "\n",
    "# For position of Sun/Earth.\n",
    "x_i = X_SUN*kpc\n",
    "grad_MW = fct.dPsi_dxi_NFW(x_i, z, rho0_MW, Mvir_MW, Rvir_MW, Rs_MW, 'MW')\n",
    "grad_MW /= (kpc/s**2)\n",
    "print('Position of Sun/Earth:')\n",
    "print(grad_MW)\n",
    "print(np.sqrt(np.sum(grad_MW**2)), '\\n')\n",
    "\n",
    "# For a position closer to the center of the halo.\n",
    "x_i = np.array([0.01, 0, 0])*kpc\n",
    "grad_MW = fct.dPsi_dxi_NFW(x_i, z, rho0_MW, Mvir_MW, Rvir_MW, Rs_MW, 'MW')\n",
    "grad_MW /= (kpc/s**2)\n",
    "print('Position close to center:')\n",
    "print(grad_MW)\n",
    "print(np.sqrt(np.sum(grad_MW**2)), '\\n')\n",
    "\n",
    "# For a position further away to the center of the halo.\n",
    "x_i = np.array([333., 0, 0])*kpc\n",
    "grad_MW = fct.dPsi_dxi_NFW(x_i, z, rho0_MW, Mvir_MW, Rvir_MW, Rs_MW, 'MW')\n",
    "grad_MW /= (kpc/s**2)\n",
    "print('Position at virial radius:')\n",
    "print(grad_MW)\n",
    "print(np.sqrt(np.sum(grad_MW**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test memory sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = np.random.random(size=(40000000,3))\n",
    "print(mem.shape, (mem.nbytes)/1e6)\n",
    "\n",
    "mem0 = np.empty((40000000,3))\n",
    "print(mem0.shape, (mem0.nbytes)/1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 million cells have ~ 1GB memory. There shouldn't be memory issues with the final arrays, especially with the SNELLIUS cluster memory nodes of ~64GB or even ~128GB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('neutrino_clustering')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0d5d0f2e48edd2cdf812a3eedd1dc78c628b894b9ae93ffd6b09cf9a60bf81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
